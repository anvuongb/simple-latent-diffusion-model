{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9abb6f1-3365-405b-a084-0aac9590fe1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/hpc/share/vuonga2/conda-env/diff/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "\n",
    "import torch\n",
    "\n",
    "from helper.painter import Painter\n",
    "from helper.trainer import Trainer\n",
    "from helper.data_generator import DataGenerator\n",
    "from helper.loader import Loader\n",
    "from helper.cond_encoder import CLIPEncoder\n",
    "\n",
    "from auto_encoder.models.variational_auto_encoder import VariationalAutoEncoder\n",
    "from clip.models.ko_clip import KoCLIPWrapper\n",
    "from diffusion_model.sampler.ddim import DDIM\n",
    "from diffusion_model.models.latent_diffusion_model import LatentDiffusionModel\n",
    "from diffusion_model.network.unet import Unet\n",
    "from diffusion_model.network.unet_wrapper import UnetWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57e2dc21-55bc-4013-af6d-46cc219ad188",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from helper.util import extract\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b803a392-d1b6-43d4-b6b0-d459e8576e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the configuration file\n",
    "CONFIG_PATH = './configs/cifar10_config.yaml'\n",
    "\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda')\n",
    "\n",
    "# Instantiate helper classes\n",
    "painter = Painter()\n",
    "loader = Loader()\n",
    "data_generator = DataGenerator()\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "data_loader = data_generator.cifar10(batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e586442-6c70-4ec8-9dec-543d4a66b314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with z of shape (1, 6, 16, 16) = 1536 dimensions.\n"
     ]
    }
   ],
   "source": [
    "vae = VariationalAutoEncoder(CONFIG_PATH) \n",
    "\n",
    "sampler = DDIM(CONFIG_PATH)  # Initialize the DDIM sampler\n",
    "network = UnetWrapper(Unet, CONFIG_PATH, None)  # Initialize the U-Net network\n",
    "ldm = LatentDiffusionModel(network, sampler, vae)  # Initialize the LDM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b49cd40e-16b8-4e28-84a4-0dabfeab5d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 301\n",
      "Training step: 29498\n",
      "Best loss: 0.0030039352250798624\n",
      "Batch size: 512\n",
      "Number of batches: 98\n",
      "===Model loaded!===\n",
      "Epoch: 304\n",
      "Training step: 118864\n",
      "Best loss: 0.22979954007031667\n",
      "Batch size: 128\n",
      "Number of batches: 391\n",
      "===Model loaded!===\n"
     ]
    }
   ],
   "source": [
    "ldm = LatentDiffusionModel(network, sampler, vae)  # Initialize the LDM\n",
    "vae = loader.model_load('models/cifar10/vae', vae, is_ema=True)\n",
    "ldm = loader.model_load('models/cifar10/ldm', ldm, is_ema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f3c56c3-74ac-459c-9fa3-7733223361b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:00, 54.44it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate samples using the trained latent diffusion model\n",
    "vae.eval()\n",
    "vae = vae.to(device)\n",
    "\n",
    "ldm.eval()\n",
    "ldm = ldm.to(device)\n",
    "\n",
    "sample = ldm.sample(n_samples=4, y = None, gamma = 0)  # Generate 4 sample images, 'y' represents any conditions, 'gamma' means guidance scale\n",
    "painter.show_images(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c829e435-402d-44cf-ac80-aaeda7745c32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDiffusionModel(\n",
       "  (sampler): DDIM(\n",
       "    (network): UnetWrapper(\n",
       "      (network): Unet(\n",
       "        (init_conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "        (time_mlp): Sequential(\n",
       "          (0): SinusoidalEmbedding()\n",
       "          (1): Linear(in_features=64, out_features=256, bias=True)\n",
       "          (2): GELU(approximate='none')\n",
       "          (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (downs): ModuleList(\n",
       "          (0): ModuleList(\n",
       "            (0-1): 2 x ResnetBlock(\n",
       "              (block1): Block(\n",
       "                (norm): AdaptiveGroupNorm(\n",
       "                  (norm): GroupNorm(32, 64, eps=1e-05, affine=False)\n",
       "                  (gamma_proj): Linear(in_features=256, out_features=64, bias=True)\n",
       "                  (beta_proj): Linear(in_features=256, out_features=64, bias=True)\n",
       "                )\n",
       "                (proj): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU()\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): AdaptiveGroupNorm(\n",
       "                  (norm): GroupNorm(32, 64, eps=1e-05, affine=False)\n",
       "                  (gamma_proj): Linear(in_features=256, out_features=64, bias=True)\n",
       "                  (beta_proj): Linear(in_features=256, out_features=64, bias=True)\n",
       "                )\n",
       "                (proj): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU()\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (res_conv): Identity()\n",
       "            )\n",
       "            (2): LinearAttention(\n",
       "              (to_qkv): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): RMSNorm()\n",
       "              )\n",
       "            )\n",
       "            (3): DownSample(\n",
       "              (downsample): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (1): ModuleList(\n",
       "            (0-1): 2 x ResnetBlock(\n",
       "              (block1): Block(\n",
       "                (norm): AdaptiveGroupNorm(\n",
       "                  (norm): GroupNorm(32, 128, eps=1e-05, affine=False)\n",
       "                  (gamma_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "                  (beta_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "                )\n",
       "                (proj): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU()\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): AdaptiveGroupNorm(\n",
       "                  (norm): GroupNorm(32, 128, eps=1e-05, affine=False)\n",
       "                  (gamma_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "                  (beta_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "                )\n",
       "                (proj): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU()\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (res_conv): Identity()\n",
       "            )\n",
       "            (2): LinearAttention(\n",
       "              (to_qkv): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): RMSNorm()\n",
       "              )\n",
       "            )\n",
       "            (3): DownSample(\n",
       "              (downsample): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (2): ModuleList(\n",
       "            (0-1): 2 x ResnetBlock(\n",
       "              (block1): Block(\n",
       "                (norm): AdaptiveGroupNorm(\n",
       "                  (norm): GroupNorm(32, 256, eps=1e-05, affine=False)\n",
       "                  (gamma_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "                  (beta_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "                )\n",
       "                (proj): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU()\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): AdaptiveGroupNorm(\n",
       "                  (norm): GroupNorm(32, 256, eps=1e-05, affine=False)\n",
       "                  (gamma_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "                  (beta_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "                )\n",
       "                (proj): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU()\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (res_conv): Identity()\n",
       "            )\n",
       "            (2): LinearAttention(\n",
       "              (to_qkv): Conv2d(256, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): RMSNorm()\n",
       "              )\n",
       "            )\n",
       "            (3): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (ups): ModuleList(\n",
       "          (0): ModuleList(\n",
       "            (0-1): 2 x ResnetBlock(\n",
       "              (block1): Block(\n",
       "                (norm): AdaptiveGroupNorm(\n",
       "                  (norm): GroupNorm(32, 768, eps=1e-05, affine=False)\n",
       "                  (gamma_proj): Linear(in_features=256, out_features=768, bias=True)\n",
       "                  (beta_proj): Linear(in_features=256, out_features=768, bias=True)\n",
       "                )\n",
       "                (proj): Conv2d(768, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU()\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): AdaptiveGroupNorm(\n",
       "                  (norm): GroupNorm(32, 512, eps=1e-05, affine=False)\n",
       "                  (gamma_proj): Linear(in_features=256, out_features=512, bias=True)\n",
       "                  (beta_proj): Linear(in_features=256, out_features=512, bias=True)\n",
       "                )\n",
       "                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU()\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (res_conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (2): Attention(\n",
       "              (to_qkv): Conv2d(512, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (to_out): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (3): UpSample(\n",
       "              (upsample): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (1): ModuleList(\n",
       "            (0-1): 2 x ResnetBlock(\n",
       "              (block1): Block(\n",
       "                (norm): AdaptiveGroupNorm(\n",
       "                  (norm): GroupNorm(32, 384, eps=1e-05, affine=False)\n",
       "                  (gamma_proj): Linear(in_features=256, out_features=384, bias=True)\n",
       "                  (beta_proj): Linear(in_features=256, out_features=384, bias=True)\n",
       "                )\n",
       "                (proj): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU()\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): AdaptiveGroupNorm(\n",
       "                  (norm): GroupNorm(32, 256, eps=1e-05, affine=False)\n",
       "                  (gamma_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "                  (beta_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "                )\n",
       "                (proj): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU()\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (res_conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (2): LinearAttention(\n",
       "              (to_qkv): Conv2d(256, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): RMSNorm()\n",
       "              )\n",
       "            )\n",
       "            (3): UpSample(\n",
       "              (upsample): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (2): ModuleList(\n",
       "            (0-1): 2 x ResnetBlock(\n",
       "              (block1): Block(\n",
       "                (norm): AdaptiveGroupNorm(\n",
       "                  (norm): GroupNorm(32, 192, eps=1e-05, affine=False)\n",
       "                  (gamma_proj): Linear(in_features=256, out_features=192, bias=True)\n",
       "                  (beta_proj): Linear(in_features=256, out_features=192, bias=True)\n",
       "                )\n",
       "                (proj): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU()\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): AdaptiveGroupNorm(\n",
       "                  (norm): GroupNorm(32, 128, eps=1e-05, affine=False)\n",
       "                  (gamma_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "                  (beta_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "                )\n",
       "                (proj): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU()\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (res_conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (2): LinearAttention(\n",
       "              (to_qkv): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): RMSNorm()\n",
       "              )\n",
       "            )\n",
       "            (3): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (mid_block1): ResnetBlock(\n",
       "          (block1): Block(\n",
       "            (norm): AdaptiveGroupNorm(\n",
       "              (norm): GroupNorm(32, 512, eps=1e-05, affine=False)\n",
       "              (gamma_proj): Linear(in_features=256, out_features=512, bias=True)\n",
       "              (beta_proj): Linear(in_features=256, out_features=512, bias=True)\n",
       "            )\n",
       "            (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (block2): Block(\n",
       "            (norm): AdaptiveGroupNorm(\n",
       "              (norm): GroupNorm(32, 512, eps=1e-05, affine=False)\n",
       "              (gamma_proj): Linear(in_features=256, out_features=512, bias=True)\n",
       "              (beta_proj): Linear(in_features=256, out_features=512, bias=True)\n",
       "            )\n",
       "            (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (res_conv): Identity()\n",
       "        )\n",
       "        (mid_attn): Attention(\n",
       "          (to_qkv): Conv2d(512, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (to_out): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (mid_block2): ResnetBlock(\n",
       "          (block1): Block(\n",
       "            (norm): AdaptiveGroupNorm(\n",
       "              (norm): GroupNorm(32, 512, eps=1e-05, affine=False)\n",
       "              (gamma_proj): Linear(in_features=256, out_features=512, bias=True)\n",
       "              (beta_proj): Linear(in_features=256, out_features=512, bias=True)\n",
       "            )\n",
       "            (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (block2): Block(\n",
       "            (norm): AdaptiveGroupNorm(\n",
       "              (norm): GroupNorm(32, 512, eps=1e-05, affine=False)\n",
       "              (gamma_proj): Linear(in_features=256, out_features=512, bias=True)\n",
       "              (beta_proj): Linear(in_features=256, out_features=512, bias=True)\n",
       "            )\n",
       "            (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (res_conv): Identity()\n",
       "        )\n",
       "        (final_res_block): ResnetBlock(\n",
       "          (block1): Block(\n",
       "            (norm): AdaptiveGroupNorm(\n",
       "              (norm): GroupNorm(32, 128, eps=1e-05, affine=False)\n",
       "              (gamma_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "              (beta_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "            )\n",
       "            (proj): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (block2): Block(\n",
       "            (norm): AdaptiveGroupNorm(\n",
       "              (norm): GroupNorm(32, 64, eps=1e-05, affine=False)\n",
       "              (gamma_proj): Linear(in_features=256, out_features=64, bias=True)\n",
       "              (beta_proj): Linear(in_features=256, out_features=64, bias=True)\n",
       "            )\n",
       "            (proj): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (res_conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (final_conv): Conv2d(64, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (cond_encoder): None\n",
       "    )\n",
       "  )\n",
       "  (network): UnetWrapper(\n",
       "    (network): Unet(\n",
       "      (init_conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "      (time_mlp): Sequential(\n",
       "        (0): SinusoidalEmbedding()\n",
       "        (1): Linear(in_features=64, out_features=256, bias=True)\n",
       "        (2): GELU(approximate='none')\n",
       "        (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "      (downs): ModuleList(\n",
       "        (0): ModuleList(\n",
       "          (0-1): 2 x ResnetBlock(\n",
       "            (block1): Block(\n",
       "              (norm): AdaptiveGroupNorm(\n",
       "                (norm): GroupNorm(32, 64, eps=1e-05, affine=False)\n",
       "                (gamma_proj): Linear(in_features=256, out_features=64, bias=True)\n",
       "                (beta_proj): Linear(in_features=256, out_features=64, bias=True)\n",
       "              )\n",
       "              (proj): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (act): SiLU()\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (norm): AdaptiveGroupNorm(\n",
       "                (norm): GroupNorm(32, 64, eps=1e-05, affine=False)\n",
       "                (gamma_proj): Linear(in_features=256, out_features=64, bias=True)\n",
       "                (beta_proj): Linear(in_features=256, out_features=64, bias=True)\n",
       "              )\n",
       "              (proj): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (act): SiLU()\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (res_conv): Identity()\n",
       "          )\n",
       "          (2): LinearAttention(\n",
       "            (to_qkv): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (to_out): Sequential(\n",
       "              (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): RMSNorm()\n",
       "            )\n",
       "          )\n",
       "          (3): DownSample(\n",
       "            (downsample): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (1): ModuleList(\n",
       "          (0-1): 2 x ResnetBlock(\n",
       "            (block1): Block(\n",
       "              (norm): AdaptiveGroupNorm(\n",
       "                (norm): GroupNorm(32, 128, eps=1e-05, affine=False)\n",
       "                (gamma_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "                (beta_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "              )\n",
       "              (proj): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (act): SiLU()\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (norm): AdaptiveGroupNorm(\n",
       "                (norm): GroupNorm(32, 128, eps=1e-05, affine=False)\n",
       "                (gamma_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "                (beta_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "              )\n",
       "              (proj): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (act): SiLU()\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (res_conv): Identity()\n",
       "          )\n",
       "          (2): LinearAttention(\n",
       "            (to_qkv): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (to_out): Sequential(\n",
       "              (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): RMSNorm()\n",
       "            )\n",
       "          )\n",
       "          (3): DownSample(\n",
       "            (downsample): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (2): ModuleList(\n",
       "          (0-1): 2 x ResnetBlock(\n",
       "            (block1): Block(\n",
       "              (norm): AdaptiveGroupNorm(\n",
       "                (norm): GroupNorm(32, 256, eps=1e-05, affine=False)\n",
       "                (gamma_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (beta_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "              )\n",
       "              (proj): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (act): SiLU()\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (norm): AdaptiveGroupNorm(\n",
       "                (norm): GroupNorm(32, 256, eps=1e-05, affine=False)\n",
       "                (gamma_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (beta_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "              )\n",
       "              (proj): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (act): SiLU()\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (res_conv): Identity()\n",
       "          )\n",
       "          (2): LinearAttention(\n",
       "            (to_qkv): Conv2d(256, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (to_out): Sequential(\n",
       "              (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): RMSNorm()\n",
       "            )\n",
       "          )\n",
       "          (3): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (ups): ModuleList(\n",
       "        (0): ModuleList(\n",
       "          (0-1): 2 x ResnetBlock(\n",
       "            (block1): Block(\n",
       "              (norm): AdaptiveGroupNorm(\n",
       "                (norm): GroupNorm(32, 768, eps=1e-05, affine=False)\n",
       "                (gamma_proj): Linear(in_features=256, out_features=768, bias=True)\n",
       "                (beta_proj): Linear(in_features=256, out_features=768, bias=True)\n",
       "              )\n",
       "              (proj): Conv2d(768, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (act): SiLU()\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (norm): AdaptiveGroupNorm(\n",
       "                (norm): GroupNorm(32, 512, eps=1e-05, affine=False)\n",
       "                (gamma_proj): Linear(in_features=256, out_features=512, bias=True)\n",
       "                (beta_proj): Linear(in_features=256, out_features=512, bias=True)\n",
       "              )\n",
       "              (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (act): SiLU()\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (res_conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (2): Attention(\n",
       "            (to_qkv): Conv2d(512, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (to_out): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (3): UpSample(\n",
       "            (upsample): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (1): ModuleList(\n",
       "          (0-1): 2 x ResnetBlock(\n",
       "            (block1): Block(\n",
       "              (norm): AdaptiveGroupNorm(\n",
       "                (norm): GroupNorm(32, 384, eps=1e-05, affine=False)\n",
       "                (gamma_proj): Linear(in_features=256, out_features=384, bias=True)\n",
       "                (beta_proj): Linear(in_features=256, out_features=384, bias=True)\n",
       "              )\n",
       "              (proj): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (act): SiLU()\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (norm): AdaptiveGroupNorm(\n",
       "                (norm): GroupNorm(32, 256, eps=1e-05, affine=False)\n",
       "                (gamma_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (beta_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "              )\n",
       "              (proj): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (act): SiLU()\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (res_conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (2): LinearAttention(\n",
       "            (to_qkv): Conv2d(256, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (to_out): Sequential(\n",
       "              (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): RMSNorm()\n",
       "            )\n",
       "          )\n",
       "          (3): UpSample(\n",
       "            (upsample): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (2): ModuleList(\n",
       "          (0-1): 2 x ResnetBlock(\n",
       "            (block1): Block(\n",
       "              (norm): AdaptiveGroupNorm(\n",
       "                (norm): GroupNorm(32, 192, eps=1e-05, affine=False)\n",
       "                (gamma_proj): Linear(in_features=256, out_features=192, bias=True)\n",
       "                (beta_proj): Linear(in_features=256, out_features=192, bias=True)\n",
       "              )\n",
       "              (proj): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (act): SiLU()\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (norm): AdaptiveGroupNorm(\n",
       "                (norm): GroupNorm(32, 128, eps=1e-05, affine=False)\n",
       "                (gamma_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "                (beta_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "              )\n",
       "              (proj): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (act): SiLU()\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (res_conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (2): LinearAttention(\n",
       "            (to_qkv): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (to_out): Sequential(\n",
       "              (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): RMSNorm()\n",
       "            )\n",
       "          )\n",
       "          (3): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (mid_block1): ResnetBlock(\n",
       "        (block1): Block(\n",
       "          (norm): AdaptiveGroupNorm(\n",
       "            (norm): GroupNorm(32, 512, eps=1e-05, affine=False)\n",
       "            (gamma_proj): Linear(in_features=256, out_features=512, bias=True)\n",
       "            (beta_proj): Linear(in_features=256, out_features=512, bias=True)\n",
       "          )\n",
       "          (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act): SiLU()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (block2): Block(\n",
       "          (norm): AdaptiveGroupNorm(\n",
       "            (norm): GroupNorm(32, 512, eps=1e-05, affine=False)\n",
       "            (gamma_proj): Linear(in_features=256, out_features=512, bias=True)\n",
       "            (beta_proj): Linear(in_features=256, out_features=512, bias=True)\n",
       "          )\n",
       "          (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act): SiLU()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (res_conv): Identity()\n",
       "      )\n",
       "      (mid_attn): Attention(\n",
       "        (to_qkv): Conv2d(512, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (to_out): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (mid_block2): ResnetBlock(\n",
       "        (block1): Block(\n",
       "          (norm): AdaptiveGroupNorm(\n",
       "            (norm): GroupNorm(32, 512, eps=1e-05, affine=False)\n",
       "            (gamma_proj): Linear(in_features=256, out_features=512, bias=True)\n",
       "            (beta_proj): Linear(in_features=256, out_features=512, bias=True)\n",
       "          )\n",
       "          (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act): SiLU()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (block2): Block(\n",
       "          (norm): AdaptiveGroupNorm(\n",
       "            (norm): GroupNorm(32, 512, eps=1e-05, affine=False)\n",
       "            (gamma_proj): Linear(in_features=256, out_features=512, bias=True)\n",
       "            (beta_proj): Linear(in_features=256, out_features=512, bias=True)\n",
       "          )\n",
       "          (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act): SiLU()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (res_conv): Identity()\n",
       "      )\n",
       "      (final_res_block): ResnetBlock(\n",
       "        (block1): Block(\n",
       "          (norm): AdaptiveGroupNorm(\n",
       "            (norm): GroupNorm(32, 128, eps=1e-05, affine=False)\n",
       "            (gamma_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (beta_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "          )\n",
       "          (proj): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act): SiLU()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (block2): Block(\n",
       "          (norm): AdaptiveGroupNorm(\n",
       "            (norm): GroupNorm(32, 64, eps=1e-05, affine=False)\n",
       "            (gamma_proj): Linear(in_features=256, out_features=64, bias=True)\n",
       "            (beta_proj): Linear(in_features=256, out_features=64, bias=True)\n",
       "          )\n",
       "          (proj): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act): SiLU()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (res_conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (final_conv): Conv2d(64, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (cond_encoder): None\n",
       "  )\n",
       "  (auto_encoder): VariationalAutoEncoder(\n",
       "    (encoder): Encoder(\n",
       "      (conv_in): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (down): ModuleList(\n",
       "        (0): Module(\n",
       "          (block): ModuleList(\n",
       "            (0-1): 2 x ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (downsample): Downsample(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2))\n",
       "          )\n",
       "        )\n",
       "        (1): Module(\n",
       "          (block): ModuleList(\n",
       "            (0): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (nin_shortcut): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (1): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (mid): Module(\n",
       "        (block_1): ResnetBlock(\n",
       "          (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (block_2): ResnetBlock(\n",
       "          (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (norm_out): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "      (conv_out): Conv2d(256, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (decoder): Decoder(\n",
       "      (conv_in): Conv2d(6, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (mid): Module(\n",
       "        (block_1): ResnetBlock(\n",
       "          (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (block_2): ResnetBlock(\n",
       "          (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (up): ModuleList(\n",
       "        (0): Module(\n",
       "          (block): ModuleList(\n",
       "            (0): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (nin_shortcut): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (1-2): 2 x ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Module(\n",
       "          (block): ModuleList(\n",
       "            (0): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (nin_shortcut): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (1-2): 2 x ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (upsample): Upsample(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm_out): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "      (conv_out): Conv2d(128, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (quant_conv): Conv2d(6, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (post_quant_conv): Conv2d(3, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampler=sampler.to(device)\n",
    "vae=vae.to(device)\n",
    "ldm = ldm.to(device)\n",
    "\n",
    "sampler.eval()\n",
    "vae.eval()\n",
    "ldm.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0650fe63-b665-4735-8ef1-46bb1ce29363",
   "metadata": {},
   "outputs": [],
   "source": [
    "sqrt_one_minus_alphas_cumprod = 1-sampler.alpha_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "465f28c1-b893-4ed9-b507-6ceb768c771b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch.func import vmap, jvp\n",
    "\n",
    "def f_only_x_one(x1, t1):\n",
    "    # x1: (1,1,H,W); t1: (1,) or scalar-like\n",
    "    t1b = t1.view(1)\n",
    "    # denom = sqrt_one_minus_alphas_cumprod[t1b.long()].reshape(1,1,1,1).detach()\n",
    "    return ldm.network(x1, t1b.long())   # -> (1,1,H,W)\n",
    "\n",
    "def f_flat_one(x1, t1):\n",
    "    return f_only_x_one(x1, t1).reshape(-1)     # -> (N=H*W,)\n",
    "\n",
    "# per-sample sub-Jacobian on the SAME input/output indices\n",
    "def subjac_one_sample_same_points(x1, t1, idxs1, chunk=None):\n",
    "    \"\"\"\n",
    "    x1:    (1,1,H,W)            single sample\n",
    "    t1:    (1,)                 single timestep\n",
    "    idxs1: (K,)                 same set for input & output\n",
    "    chunk: int or None          optional micro-batch over K\n",
    "\n",
    "    returns: J_sub (K,K), diag (K,)\n",
    "    \"\"\"\n",
    "    N = x1.numel()                       # = H*W (since C=1)\n",
    "    K = idxs1.numel()\n",
    "\n",
    "    def jvp_one(v_i):\n",
    "        # returns J v_i (shape N,)\n",
    "        return jvp(lambda z: f_flat_one(z, t1), (x1,), (v_i,))[1]\n",
    "\n",
    "    if chunk is None:\n",
    "        V = F.one_hot(idxs1, num_classes=N).to(x1).view(K, *x1.shape)   # (K,1,1,H,W)\n",
    "        Jvs = vmap(jvp_one)(V)                                          # (K, N)\n",
    "    else:\n",
    "        parts = []\n",
    "        for part in idxs1.split(chunk):\n",
    "            Vp = F.one_hot(part, num_classes=N).to(x1).view(-1, *x1.shape)\n",
    "            parts.append(vmap(jvp_one)(Vp))                              # (c, N)\n",
    "        Jvs = torch.cat(parts, dim=0)                                    # (K, N)\n",
    "\n",
    "    J_sub = Jvs[:, idxs1].T.contiguous()                                 # (K, K)\n",
    "    diag  = Jvs[torch.arange(K, device=x1.device), idxs1].contiguous()   # (K,)\n",
    "    return J_sub, diag\n",
    "\n",
    "# batch wrapper: loop over B in Python (no vmap over batch)\n",
    "def subjac_batch_same_points(x, t, idxs_flat, per_sample=False, chunk=None):\n",
    "    \"\"\"\n",
    "    x:          (B,1,H,W)\n",
    "    t:          (B,)\n",
    "    idxs_flat:  (K,) if per_sample=False (shared points across batch)\n",
    "                (B,K) if per_sample=True  (different points per sample)\n",
    "    returns: J_sub (B,K,K), diag (B,K)\n",
    "    \"\"\"\n",
    "    B = x.size(0)\n",
    "    J_list, d_list = [], []\n",
    "    for b in range(B):\n",
    "        idxs_b = idxs_flat[b] if per_sample else idxs_flat\n",
    "        Jb, db = subjac_one_sample_same_points(x[b:b+1], t[b:b+1], idxs_b, chunk=chunk)\n",
    "        J_list.append(Jb)\n",
    "        d_list.append(db)\n",
    "    return torch.stack(J_list, dim=0), torch.stack(d_list, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0611626-ab80-41b4-b223-3a5caa94efb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch 17:   3%|▎         | 3/100 [01:37<44:33, 27.56s/it]"
     ]
    }
   ],
   "source": [
    "N_sim = 1000\n",
    "skip = 10\n",
    "Js = []\n",
    "batch_size = 4\n",
    "C, H, W = 3, 16, 16\n",
    "K = 64\n",
    "pbar = tqdm.tqdm(range(1, N_sim, skip))\n",
    "for t_in in pbar:\n",
    "    Js_tmp = []\n",
    "    # reset data\n",
    "    data_loader = data_generator.cifar10(batch_size=batch_size, shuffle=False)\n",
    "    for idx, (x0, _) in enumerate(data_loader):\n",
    "        pbar.set_description(f\"batch {idx}\")\n",
    "        if idx >= 32: # collect from 128 images only\n",
    "            break\n",
    "        x0 = x0.to(device)\n",
    "        x0 = vae.encode(x0).sample().to(device)\n",
    "        \n",
    "        t = torch.ones(batch_size,).long().to(device)*t_in\n",
    "        x0_noised = sampler.q_sample(x0, t)\n",
    "        \n",
    "        # get scores & jacobian\n",
    "        \n",
    "        idxs_per = torch.stack([torch.randperm(C*H*W, device=x0_noised.device)[:K] for _ in range(batch_size)], dim=0)\n",
    "        J_sub, _ = subjac_batch_same_points(x0_noised, t, idxs_per, per_sample=True, chunk=16) # (batch, 64, 64)\n",
    "        \n",
    "        Js_tmp.append(J_sub.detach().cpu().numpy())\n",
    "    Js.append(np.vstack(Js_tmp))\n",
    "\n",
    "np.save(f'stats/jacobian_ldm_t{N_sim}', np.array(Js))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60a146f-f950-43a6-854f-53663ef982b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diff",
   "language": "python",
   "name": "diff"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
