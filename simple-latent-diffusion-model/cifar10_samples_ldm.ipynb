{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a493da9b-2a5c-4e64-8766-170c8b4cf3ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/hpc/share/vuonga2/conda-env/diff/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "\n",
    "import torch\n",
    "\n",
    "from helper.painter import Painter\n",
    "from helper.trainer import Trainer\n",
    "from helper.data_generator import DataGenerator\n",
    "from helper.loader import Loader\n",
    "from helper.cond_encoder import CLIPEncoder\n",
    "\n",
    "from auto_encoder.models.variational_auto_encoder import VariationalAutoEncoder\n",
    "from clip.models.ko_clip import KoCLIPWrapper\n",
    "from diffusion_model.sampler.ddim import DDIM\n",
    "from diffusion_model.models.latent_diffusion_model import LatentDiffusionModel\n",
    "from diffusion_model.network.unet import Unet\n",
    "from diffusion_model.network.unet_wrapper import UnetWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47545d28-10c5-4ef7-8850-9bd6a53238de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from helper.util import extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a396e3d-dada-4fa7-8c4d-9973486b8d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the configuration file\n",
    "CONFIG_PATH = './configs/cifar10_config.yaml'\n",
    "\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda')\n",
    "\n",
    "# Instantiate helper classes\n",
    "painter = Painter()\n",
    "loader = Loader()\n",
    "data_generator = DataGenerator()\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "data_loader = data_generator.cifar10(batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e09b7e8-9cb6-40bb-85ba-21d31e915964",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VariationalAutoEncoder(\n",
       "  (encoder): Encoder(\n",
       "    (conv_in): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (down): ModuleList(\n",
       "      (0): Module(\n",
       "        (block): ModuleList(\n",
       "          (0-1): 2 x ResnetBlock(\n",
       "            (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (downsample): Downsample(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2))\n",
       "        )\n",
       "      )\n",
       "      (1): Module(\n",
       "        (block): ModuleList(\n",
       "          (0): ResnetBlock(\n",
       "            (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "            (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nin_shortcut): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): ResnetBlock(\n",
       "            (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (mid): Module(\n",
       "      (block_1): ResnetBlock(\n",
       "        (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (block_2): ResnetBlock(\n",
       "        (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (norm_out): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "    (conv_out): Conv2d(256, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (conv_in): Conv2d(6, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (mid): Module(\n",
       "      (block_1): ResnetBlock(\n",
       "        (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (block_2): ResnetBlock(\n",
       "        (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (up): ModuleList(\n",
       "      (0): Module(\n",
       "        (block): ModuleList(\n",
       "          (0): ResnetBlock(\n",
       "            (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "            (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nin_shortcut): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1-2): 2 x ResnetBlock(\n",
       "            (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): Module(\n",
       "        (block): ModuleList(\n",
       "          (0): ResnetBlock(\n",
       "            (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "            (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nin_shortcut): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1-2): 2 x ResnetBlock(\n",
       "            (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (upsample): Upsample(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm_out): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "    (conv_out): Conv2d(128, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (quant_conv): Conv2d(6, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (post_quant_conv): Conv2d(3, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8012ef15-6cf9-4b35-b9c6-f8a2181bbd78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with z of shape (1, 6, 16, 16) = 1536 dimensions.\n"
     ]
    }
   ],
   "source": [
    "vae = VariationalAutoEncoder(CONFIG_PATH) \n",
    "\n",
    "sampler = DDIM(CONFIG_PATH)  # Initialize the DDIM sampler\n",
    "network = UnetWrapper(Unet, CONFIG_PATH, None)  # Initialize the U-Net network\n",
    "ldm = LatentDiffusionModel(network, sampler, vae)  # Initialize the LDM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0171f5ed-8c4b-41e6-8884-9c976986f06f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 301\n",
      "Training step: 29498\n",
      "Best loss: 0.0030039352250798624\n",
      "Batch size: 512\n",
      "Number of batches: 98\n",
      "===Model loaded!===\n",
      "Epoch: 304\n",
      "Training step: 118864\n",
      "Best loss: 0.22979954007031667\n",
      "Batch size: 128\n",
      "Number of batches: 391\n",
      "===Model loaded!===\n"
     ]
    }
   ],
   "source": [
    "ldm = LatentDiffusionModel(network, sampler, vae)  # Initialize the LDM\n",
    "vae = loader.model_load('models/cifar10/vae', vae, is_ema=True)\n",
    "ldm = loader.model_load('models/cifar10/ldm', ldm, is_ema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81eb18c3-50ac-48a4-a126-c9e01f1a0b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:00, 75.16it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate samples using the trained latent diffusion model\n",
    "vae.eval()\n",
    "vae = vae.to(device)\n",
    "\n",
    "ldm.eval()\n",
    "ldm = ldm.to(device)\n",
    "\n",
    "sample = ldm.sample(n_samples=4, y = None, gamma = 0)  # Generate 4 sample images, 'y' represents any conditions, 'gamma' means guidance scale\n",
    "painter.show_images(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5da1251-937b-4e26-a2e0-24bd6107d05a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDiffusionModel(\n",
       "  (sampler): DDIM(\n",
       "    (network): UnetWrapper(\n",
       "      (network): Unet(\n",
       "        (init_conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "        (time_mlp): Sequential(\n",
       "          (0): SinusoidalEmbedding()\n",
       "          (1): Linear(in_features=64, out_features=256, bias=True)\n",
       "          (2): GELU(approximate='none')\n",
       "          (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (downs): ModuleList(\n",
       "          (0): ModuleList(\n",
       "            (0-1): 2 x ResnetBlock(\n",
       "              (block1): Block(\n",
       "                (norm): AdaptiveGroupNorm(\n",
       "                  (norm): GroupNorm(32, 64, eps=1e-05, affine=False)\n",
       "                  (gamma_proj): Linear(in_features=256, out_features=64, bias=True)\n",
       "                  (beta_proj): Linear(in_features=256, out_features=64, bias=True)\n",
       "                )\n",
       "                (proj): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU()\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): AdaptiveGroupNorm(\n",
       "                  (norm): GroupNorm(32, 64, eps=1e-05, affine=False)\n",
       "                  (gamma_proj): Linear(in_features=256, out_features=64, bias=True)\n",
       "                  (beta_proj): Linear(in_features=256, out_features=64, bias=True)\n",
       "                )\n",
       "                (proj): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU()\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (res_conv): Identity()\n",
       "            )\n",
       "            (2): LinearAttention(\n",
       "              (to_qkv): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): RMSNorm()\n",
       "              )\n",
       "            )\n",
       "            (3): DownSample(\n",
       "              (downsample): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (1): ModuleList(\n",
       "            (0-1): 2 x ResnetBlock(\n",
       "              (block1): Block(\n",
       "                (norm): AdaptiveGroupNorm(\n",
       "                  (norm): GroupNorm(32, 128, eps=1e-05, affine=False)\n",
       "                  (gamma_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "                  (beta_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "                )\n",
       "                (proj): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU()\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): AdaptiveGroupNorm(\n",
       "                  (norm): GroupNorm(32, 128, eps=1e-05, affine=False)\n",
       "                  (gamma_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "                  (beta_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "                )\n",
       "                (proj): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU()\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (res_conv): Identity()\n",
       "            )\n",
       "            (2): LinearAttention(\n",
       "              (to_qkv): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): RMSNorm()\n",
       "              )\n",
       "            )\n",
       "            (3): DownSample(\n",
       "              (downsample): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (2): ModuleList(\n",
       "            (0-1): 2 x ResnetBlock(\n",
       "              (block1): Block(\n",
       "                (norm): AdaptiveGroupNorm(\n",
       "                  (norm): GroupNorm(32, 256, eps=1e-05, affine=False)\n",
       "                  (gamma_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "                  (beta_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "                )\n",
       "                (proj): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU()\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): AdaptiveGroupNorm(\n",
       "                  (norm): GroupNorm(32, 256, eps=1e-05, affine=False)\n",
       "                  (gamma_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "                  (beta_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "                )\n",
       "                (proj): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU()\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (res_conv): Identity()\n",
       "            )\n",
       "            (2): LinearAttention(\n",
       "              (to_qkv): Conv2d(256, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): RMSNorm()\n",
       "              )\n",
       "            )\n",
       "            (3): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (ups): ModuleList(\n",
       "          (0): ModuleList(\n",
       "            (0-1): 2 x ResnetBlock(\n",
       "              (block1): Block(\n",
       "                (norm): AdaptiveGroupNorm(\n",
       "                  (norm): GroupNorm(32, 768, eps=1e-05, affine=False)\n",
       "                  (gamma_proj): Linear(in_features=256, out_features=768, bias=True)\n",
       "                  (beta_proj): Linear(in_features=256, out_features=768, bias=True)\n",
       "                )\n",
       "                (proj): Conv2d(768, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU()\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): AdaptiveGroupNorm(\n",
       "                  (norm): GroupNorm(32, 512, eps=1e-05, affine=False)\n",
       "                  (gamma_proj): Linear(in_features=256, out_features=512, bias=True)\n",
       "                  (beta_proj): Linear(in_features=256, out_features=512, bias=True)\n",
       "                )\n",
       "                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU()\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (res_conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (2): Attention(\n",
       "              (to_qkv): Conv2d(512, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (to_out): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (3): UpSample(\n",
       "              (upsample): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (1): ModuleList(\n",
       "            (0-1): 2 x ResnetBlock(\n",
       "              (block1): Block(\n",
       "                (norm): AdaptiveGroupNorm(\n",
       "                  (norm): GroupNorm(32, 384, eps=1e-05, affine=False)\n",
       "                  (gamma_proj): Linear(in_features=256, out_features=384, bias=True)\n",
       "                  (beta_proj): Linear(in_features=256, out_features=384, bias=True)\n",
       "                )\n",
       "                (proj): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU()\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): AdaptiveGroupNorm(\n",
       "                  (norm): GroupNorm(32, 256, eps=1e-05, affine=False)\n",
       "                  (gamma_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "                  (beta_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "                )\n",
       "                (proj): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU()\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (res_conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (2): LinearAttention(\n",
       "              (to_qkv): Conv2d(256, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): RMSNorm()\n",
       "              )\n",
       "            )\n",
       "            (3): UpSample(\n",
       "              (upsample): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (2): ModuleList(\n",
       "            (0-1): 2 x ResnetBlock(\n",
       "              (block1): Block(\n",
       "                (norm): AdaptiveGroupNorm(\n",
       "                  (norm): GroupNorm(32, 192, eps=1e-05, affine=False)\n",
       "                  (gamma_proj): Linear(in_features=256, out_features=192, bias=True)\n",
       "                  (beta_proj): Linear(in_features=256, out_features=192, bias=True)\n",
       "                )\n",
       "                (proj): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU()\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): AdaptiveGroupNorm(\n",
       "                  (norm): GroupNorm(32, 128, eps=1e-05, affine=False)\n",
       "                  (gamma_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "                  (beta_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "                )\n",
       "                (proj): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU()\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (res_conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (2): LinearAttention(\n",
       "              (to_qkv): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): RMSNorm()\n",
       "              )\n",
       "            )\n",
       "            (3): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (mid_block1): ResnetBlock(\n",
       "          (block1): Block(\n",
       "            (norm): AdaptiveGroupNorm(\n",
       "              (norm): GroupNorm(32, 512, eps=1e-05, affine=False)\n",
       "              (gamma_proj): Linear(in_features=256, out_features=512, bias=True)\n",
       "              (beta_proj): Linear(in_features=256, out_features=512, bias=True)\n",
       "            )\n",
       "            (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (block2): Block(\n",
       "            (norm): AdaptiveGroupNorm(\n",
       "              (norm): GroupNorm(32, 512, eps=1e-05, affine=False)\n",
       "              (gamma_proj): Linear(in_features=256, out_features=512, bias=True)\n",
       "              (beta_proj): Linear(in_features=256, out_features=512, bias=True)\n",
       "            )\n",
       "            (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (res_conv): Identity()\n",
       "        )\n",
       "        (mid_attn): Attention(\n",
       "          (to_qkv): Conv2d(512, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (to_out): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (mid_block2): ResnetBlock(\n",
       "          (block1): Block(\n",
       "            (norm): AdaptiveGroupNorm(\n",
       "              (norm): GroupNorm(32, 512, eps=1e-05, affine=False)\n",
       "              (gamma_proj): Linear(in_features=256, out_features=512, bias=True)\n",
       "              (beta_proj): Linear(in_features=256, out_features=512, bias=True)\n",
       "            )\n",
       "            (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (block2): Block(\n",
       "            (norm): AdaptiveGroupNorm(\n",
       "              (norm): GroupNorm(32, 512, eps=1e-05, affine=False)\n",
       "              (gamma_proj): Linear(in_features=256, out_features=512, bias=True)\n",
       "              (beta_proj): Linear(in_features=256, out_features=512, bias=True)\n",
       "            )\n",
       "            (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (res_conv): Identity()\n",
       "        )\n",
       "        (final_res_block): ResnetBlock(\n",
       "          (block1): Block(\n",
       "            (norm): AdaptiveGroupNorm(\n",
       "              (norm): GroupNorm(32, 128, eps=1e-05, affine=False)\n",
       "              (gamma_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "              (beta_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "            )\n",
       "            (proj): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (block2): Block(\n",
       "            (norm): AdaptiveGroupNorm(\n",
       "              (norm): GroupNorm(32, 64, eps=1e-05, affine=False)\n",
       "              (gamma_proj): Linear(in_features=256, out_features=64, bias=True)\n",
       "              (beta_proj): Linear(in_features=256, out_features=64, bias=True)\n",
       "            )\n",
       "            (proj): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (res_conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (final_conv): Conv2d(64, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (cond_encoder): None\n",
       "    )\n",
       "  )\n",
       "  (network): UnetWrapper(\n",
       "    (network): Unet(\n",
       "      (init_conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "      (time_mlp): Sequential(\n",
       "        (0): SinusoidalEmbedding()\n",
       "        (1): Linear(in_features=64, out_features=256, bias=True)\n",
       "        (2): GELU(approximate='none')\n",
       "        (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "      (downs): ModuleList(\n",
       "        (0): ModuleList(\n",
       "          (0-1): 2 x ResnetBlock(\n",
       "            (block1): Block(\n",
       "              (norm): AdaptiveGroupNorm(\n",
       "                (norm): GroupNorm(32, 64, eps=1e-05, affine=False)\n",
       "                (gamma_proj): Linear(in_features=256, out_features=64, bias=True)\n",
       "                (beta_proj): Linear(in_features=256, out_features=64, bias=True)\n",
       "              )\n",
       "              (proj): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (act): SiLU()\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (norm): AdaptiveGroupNorm(\n",
       "                (norm): GroupNorm(32, 64, eps=1e-05, affine=False)\n",
       "                (gamma_proj): Linear(in_features=256, out_features=64, bias=True)\n",
       "                (beta_proj): Linear(in_features=256, out_features=64, bias=True)\n",
       "              )\n",
       "              (proj): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (act): SiLU()\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (res_conv): Identity()\n",
       "          )\n",
       "          (2): LinearAttention(\n",
       "            (to_qkv): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (to_out): Sequential(\n",
       "              (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): RMSNorm()\n",
       "            )\n",
       "          )\n",
       "          (3): DownSample(\n",
       "            (downsample): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (1): ModuleList(\n",
       "          (0-1): 2 x ResnetBlock(\n",
       "            (block1): Block(\n",
       "              (norm): AdaptiveGroupNorm(\n",
       "                (norm): GroupNorm(32, 128, eps=1e-05, affine=False)\n",
       "                (gamma_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "                (beta_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "              )\n",
       "              (proj): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (act): SiLU()\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (norm): AdaptiveGroupNorm(\n",
       "                (norm): GroupNorm(32, 128, eps=1e-05, affine=False)\n",
       "                (gamma_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "                (beta_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "              )\n",
       "              (proj): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (act): SiLU()\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (res_conv): Identity()\n",
       "          )\n",
       "          (2): LinearAttention(\n",
       "            (to_qkv): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (to_out): Sequential(\n",
       "              (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): RMSNorm()\n",
       "            )\n",
       "          )\n",
       "          (3): DownSample(\n",
       "            (downsample): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (2): ModuleList(\n",
       "          (0-1): 2 x ResnetBlock(\n",
       "            (block1): Block(\n",
       "              (norm): AdaptiveGroupNorm(\n",
       "                (norm): GroupNorm(32, 256, eps=1e-05, affine=False)\n",
       "                (gamma_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (beta_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "              )\n",
       "              (proj): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (act): SiLU()\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (norm): AdaptiveGroupNorm(\n",
       "                (norm): GroupNorm(32, 256, eps=1e-05, affine=False)\n",
       "                (gamma_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (beta_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "              )\n",
       "              (proj): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (act): SiLU()\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (res_conv): Identity()\n",
       "          )\n",
       "          (2): LinearAttention(\n",
       "            (to_qkv): Conv2d(256, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (to_out): Sequential(\n",
       "              (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): RMSNorm()\n",
       "            )\n",
       "          )\n",
       "          (3): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (ups): ModuleList(\n",
       "        (0): ModuleList(\n",
       "          (0-1): 2 x ResnetBlock(\n",
       "            (block1): Block(\n",
       "              (norm): AdaptiveGroupNorm(\n",
       "                (norm): GroupNorm(32, 768, eps=1e-05, affine=False)\n",
       "                (gamma_proj): Linear(in_features=256, out_features=768, bias=True)\n",
       "                (beta_proj): Linear(in_features=256, out_features=768, bias=True)\n",
       "              )\n",
       "              (proj): Conv2d(768, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (act): SiLU()\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (norm): AdaptiveGroupNorm(\n",
       "                (norm): GroupNorm(32, 512, eps=1e-05, affine=False)\n",
       "                (gamma_proj): Linear(in_features=256, out_features=512, bias=True)\n",
       "                (beta_proj): Linear(in_features=256, out_features=512, bias=True)\n",
       "              )\n",
       "              (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (act): SiLU()\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (res_conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (2): Attention(\n",
       "            (to_qkv): Conv2d(512, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (to_out): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (3): UpSample(\n",
       "            (upsample): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (1): ModuleList(\n",
       "          (0-1): 2 x ResnetBlock(\n",
       "            (block1): Block(\n",
       "              (norm): AdaptiveGroupNorm(\n",
       "                (norm): GroupNorm(32, 384, eps=1e-05, affine=False)\n",
       "                (gamma_proj): Linear(in_features=256, out_features=384, bias=True)\n",
       "                (beta_proj): Linear(in_features=256, out_features=384, bias=True)\n",
       "              )\n",
       "              (proj): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (act): SiLU()\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (norm): AdaptiveGroupNorm(\n",
       "                (norm): GroupNorm(32, 256, eps=1e-05, affine=False)\n",
       "                (gamma_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (beta_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "              )\n",
       "              (proj): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (act): SiLU()\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (res_conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (2): LinearAttention(\n",
       "            (to_qkv): Conv2d(256, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (to_out): Sequential(\n",
       "              (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): RMSNorm()\n",
       "            )\n",
       "          )\n",
       "          (3): UpSample(\n",
       "            (upsample): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (2): ModuleList(\n",
       "          (0-1): 2 x ResnetBlock(\n",
       "            (block1): Block(\n",
       "              (norm): AdaptiveGroupNorm(\n",
       "                (norm): GroupNorm(32, 192, eps=1e-05, affine=False)\n",
       "                (gamma_proj): Linear(in_features=256, out_features=192, bias=True)\n",
       "                (beta_proj): Linear(in_features=256, out_features=192, bias=True)\n",
       "              )\n",
       "              (proj): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (act): SiLU()\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (norm): AdaptiveGroupNorm(\n",
       "                (norm): GroupNorm(32, 128, eps=1e-05, affine=False)\n",
       "                (gamma_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "                (beta_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "              )\n",
       "              (proj): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (act): SiLU()\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (res_conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (2): LinearAttention(\n",
       "            (to_qkv): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (to_out): Sequential(\n",
       "              (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): RMSNorm()\n",
       "            )\n",
       "          )\n",
       "          (3): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (mid_block1): ResnetBlock(\n",
       "        (block1): Block(\n",
       "          (norm): AdaptiveGroupNorm(\n",
       "            (norm): GroupNorm(32, 512, eps=1e-05, affine=False)\n",
       "            (gamma_proj): Linear(in_features=256, out_features=512, bias=True)\n",
       "            (beta_proj): Linear(in_features=256, out_features=512, bias=True)\n",
       "          )\n",
       "          (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act): SiLU()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (block2): Block(\n",
       "          (norm): AdaptiveGroupNorm(\n",
       "            (norm): GroupNorm(32, 512, eps=1e-05, affine=False)\n",
       "            (gamma_proj): Linear(in_features=256, out_features=512, bias=True)\n",
       "            (beta_proj): Linear(in_features=256, out_features=512, bias=True)\n",
       "          )\n",
       "          (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act): SiLU()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (res_conv): Identity()\n",
       "      )\n",
       "      (mid_attn): Attention(\n",
       "        (to_qkv): Conv2d(512, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (to_out): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (mid_block2): ResnetBlock(\n",
       "        (block1): Block(\n",
       "          (norm): AdaptiveGroupNorm(\n",
       "            (norm): GroupNorm(32, 512, eps=1e-05, affine=False)\n",
       "            (gamma_proj): Linear(in_features=256, out_features=512, bias=True)\n",
       "            (beta_proj): Linear(in_features=256, out_features=512, bias=True)\n",
       "          )\n",
       "          (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act): SiLU()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (block2): Block(\n",
       "          (norm): AdaptiveGroupNorm(\n",
       "            (norm): GroupNorm(32, 512, eps=1e-05, affine=False)\n",
       "            (gamma_proj): Linear(in_features=256, out_features=512, bias=True)\n",
       "            (beta_proj): Linear(in_features=256, out_features=512, bias=True)\n",
       "          )\n",
       "          (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act): SiLU()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (res_conv): Identity()\n",
       "      )\n",
       "      (final_res_block): ResnetBlock(\n",
       "        (block1): Block(\n",
       "          (norm): AdaptiveGroupNorm(\n",
       "            (norm): GroupNorm(32, 128, eps=1e-05, affine=False)\n",
       "            (gamma_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (beta_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "          )\n",
       "          (proj): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act): SiLU()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (block2): Block(\n",
       "          (norm): AdaptiveGroupNorm(\n",
       "            (norm): GroupNorm(32, 64, eps=1e-05, affine=False)\n",
       "            (gamma_proj): Linear(in_features=256, out_features=64, bias=True)\n",
       "            (beta_proj): Linear(in_features=256, out_features=64, bias=True)\n",
       "          )\n",
       "          (proj): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act): SiLU()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (res_conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (final_conv): Conv2d(64, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (cond_encoder): None\n",
       "  )\n",
       "  (auto_encoder): VariationalAutoEncoder(\n",
       "    (encoder): Encoder(\n",
       "      (conv_in): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (down): ModuleList(\n",
       "        (0): Module(\n",
       "          (block): ModuleList(\n",
       "            (0-1): 2 x ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (downsample): Downsample(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2))\n",
       "          )\n",
       "        )\n",
       "        (1): Module(\n",
       "          (block): ModuleList(\n",
       "            (0): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (nin_shortcut): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (1): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (mid): Module(\n",
       "        (block_1): ResnetBlock(\n",
       "          (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (block_2): ResnetBlock(\n",
       "          (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (norm_out): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "      (conv_out): Conv2d(256, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (decoder): Decoder(\n",
       "      (conv_in): Conv2d(6, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (mid): Module(\n",
       "        (block_1): ResnetBlock(\n",
       "          (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (block_2): ResnetBlock(\n",
       "          (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (up): ModuleList(\n",
       "        (0): Module(\n",
       "          (block): ModuleList(\n",
       "            (0): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (nin_shortcut): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (1-2): 2 x ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Module(\n",
       "          (block): ModuleList(\n",
       "            (0): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (nin_shortcut): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (1-2): 2 x ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (upsample): Upsample(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm_out): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "      (conv_out): Conv2d(128, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (quant_conv): Conv2d(6, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (post_quant_conv): Conv2d(3, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampler=sampler.to(device)\n",
    "vae=vae.to(device)\n",
    "ldm = ldm.to(device)\n",
    "\n",
    "sampler.eval()\n",
    "vae.eval()\n",
    "ldm.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68ec48b-389e-4ed9-b2ad-275b0475cf5b",
   "metadata": {},
   "source": [
    "## compute jacobian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "66f26af5-0593-4366-afda-90cdff033fae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch 1: 100%|| 100/100 [07:13<00:00,  4.33s/it]\n"
     ]
    }
   ],
   "source": [
    "N_sim = 1000\n",
    "skip = 10\n",
    "Js = []\n",
    "batch_size = 2\n",
    "\n",
    "def f(x, t):\n",
    "    return ldm.network(x, t.long())\n",
    "\n",
    "pbar = tqdm.tqdm(range(1, N_sim, skip))\n",
    "for t_in in pbar:\n",
    "    Js_tmp = []\n",
    "    # reset data\n",
    "    data_loader = data_generator.cifar10(batch_size=batch_size)\n",
    "    for idx, (x0, _) in enumerate(data_loader):\n",
    "        pbar.set_description(f\"batch {idx}\")\n",
    "        if idx >= 1: # collect from 128 images only\n",
    "            break\n",
    "        x0 = x0.to(device)\n",
    "        x0 = vae.encode(x0).sample().to(device)\n",
    "        \n",
    "        t = torch.ones(batch_size,).long().to(device)*t_in\n",
    "        x0_noised = sampler.q_sample(x0, t)\n",
    "        \n",
    "        # get scores & jacobian\n",
    "        \n",
    "        t_grad = t.clone().detach().requires_grad_(False)\n",
    "        x_grad = x0_noised.clone().detach().requires_grad_(True).to(device)\n",
    "        J, _ = torch.autograd.functional.jacobian(f, (x_grad, t_grad.float()), vectorize=True)\n",
    "        Jr = J.reshape(batch_size, 3*16*16, batch_size, 3*16*16)\n",
    "        Js_tmp.append(Jr.cpu().numpy())\n",
    "    Js.append(Js_tmp)\n",
    "\n",
    "np.save(f'stats/jacobian_ldm_t{N_sim}', np.array(Js))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f61704d-40dd-4892-a462-dbecaaa14a73",
   "metadata": {},
   "source": [
    "## sample paths methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db1199af-8db6-4fdd-a389-b80ad599ec71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mike_periodic_bridge(x, y, steps):\n",
    "    x = x.detach().cpu().numpy()\n",
    "    y = y.detach().cpu().numpy()\n",
    "    ## split in to pairs of pixels\n",
    "    inds=np.arange(x.size).reshape((-1,1))\n",
    "    xsize = x[0].size #size of 1 image\n",
    "    # shuffle the indices\n",
    "    for i in range(0, xsize*batch_size, xsize):\n",
    "        tmp = inds[i:i+xsize]\n",
    "        np.random.shuffle(tmp)\n",
    "        inds[i:i+xsize] = tmp\n",
    "\n",
    "    s = xsize // 2\n",
    "    ind_pairs = np.array([np.stack((inds[i*s*2:i*s*2 + s], inds[i*s*2 + s:i*s*2 + 2*s])) for i in range(batch_size)])\n",
    "    # print(ind_pairs.shape)\n",
    "    centers = x[np.unravel_index(ind_pairs, x.shape)] # centers[:, i] == x[ind_pairs[0, i]], x[ind_pairs[1, i]] (where indexing is implicitly unraveled)\n",
    "    points = y[np.unravel_index(ind_pairs, y.shape)]\n",
    "    radii = np.sqrt(np.sum((centers - points) ** 2, axis=1))\n",
    "    thetas = np.arctan2((points - centers)[:,1,...], (points - centers)[:,0,...])\n",
    "    # print(centers.shape, points.shape, x.shape)\n",
    "    \n",
    "    radii = radii[:,None,:,:]\n",
    "    thetas = thetas[:,None,:,:]\n",
    "    # print(radii.shape, thetas.shape)\n",
    "    \n",
    "    def make_image(theta, x):\n",
    "        new_points = centers + radii * np.concatenate([np.cos(thetas + theta), np.sin(thetas + theta)], axis=1)\n",
    "\n",
    "        ind_0 = ind_pairs[:,0,...]\n",
    "        ind_1 = ind_pairs[:,1,...]\n",
    "        # print(new_points.shape)\n",
    "        x[np.unravel_index(ind_0, x.shape)] = new_points[:,0,...]\n",
    "        x[np.unravel_index(ind_1, x.shape)] = new_points[:,1,...]\n",
    "        return x\n",
    "        \n",
    "    y_rot = np.zeros_like(x)\n",
    "    bridge = []\n",
    "    for i, theta in enumerate(np.linspace(0, 2*np.pi, steps, endpoint=False)):\n",
    "        y_rot = make_image(theta, y_rot)\n",
    "        bridge.append(torch.from_numpy(y_rot.copy()))\n",
    "\n",
    "    bridge.append(bridge[0]) #closed-loop\n",
    "    return bridge\n",
    "\n",
    "def brownian_bridge(x, steps, sigma, T=1000):\n",
    "    x_t = x.clone()\n",
    "    bridge = [x_t.cpu()]\n",
    "        \n",
    "    # Construct Brownian bridge\n",
    "    for t in range(1, T):\n",
    "        eps = sigma * torch.randn_like(x)\n",
    "        correction = (x - x_t) / (steps - t + 1)\n",
    "        x_t = x_t + eps + correction\n",
    "        bridge.append(x_t.cpu())\n",
    "        \n",
    "    # append initial point to form closed-loop\n",
    "    bridge.append(bridge[0].cpu())\n",
    "    return bridge\n",
    "\n",
    "def cheapshot_bridge(x, steps, t):\n",
    "    # generate steps//10 random images:\n",
    "    bridge_tmp = []\n",
    "    for i in range(steps//10):\n",
    "        noise = torch.randn_like(x)\n",
    "        tin = torch.ones(batch_size).long() * t\n",
    "        xt = sampler.q_sample(x0, tin.to(device))\n",
    "        bridge_tmp.append(xt.cpu())\n",
    "    bridge_tmp.append(bridge_tmp[0]) # close loop\n",
    "    \n",
    "    bridge = [0 for i in range(steps+1)]\n",
    "    bridge[0] = bridge_tmp[0]\n",
    "    bridge[-1] = bridge_tmp[-1]\n",
    "    \n",
    "    for i in range(1, steps):\n",
    "        if i%10 == 0:\n",
    "            bridge[i] = bridge_tmp[i//10]\n",
    "        else:\n",
    "            alpha = (i%10)/10.0\n",
    "            bridge[i] = (1-alpha)*bridge_tmp[i//10] + alpha*bridge_tmp[i//10+1]\n",
    "\n",
    "    return bridge\n",
    "\n",
    "def cheapshot_bridge_yt(x, t, size):\n",
    "    def get_noised(x, t):\n",
    "        tin = torch.ones(x.shape[0]).long() * t\n",
    "        xt = sampler.q_sample(x0, tin.to(device))\n",
    "        return xt\n",
    "        \n",
    "    def interpolate(X0, X1, X2, sqrt_alphas, sqrt_one_minus_alphas, L=100):\n",
    "        # interpolate between X1->X2,\n",
    "        # with projection back on to X0 manifold\n",
    "\n",
    "        # linearly interpolate in between each dimension, as some initial guess\n",
    "        X12 = np.zeros((x.shape[0], L, 3, size, size))\n",
    "        \n",
    "        for b in range(x.shape[0]):\n",
    "            for i in range(size):\n",
    "                for j in range(size):\n",
    "                    for k in range(3):\n",
    "                        X12[b,:,k,i,j] = np.interp( np.linspace(0,1,L), [0,1], [X1[b,k,i,j], X2[b,k,i,j]])\n",
    "    \n",
    "        # matching the gamma from ddpm with YT's\n",
    "        r1 = np.sqrt(np.sum(((X1 - X0*sqrt_alphas)/sqrt_one_minus_alphas)**2))\n",
    "        r2 = np.sqrt(np.sum(((X2 - X0*sqrt_alphas)/sqrt_one_minus_alphas)**2))\n",
    "        r_array = np.interp( np.linspace(0,1,L), [0,1], [r1,r2] ) \n",
    "    \n",
    "        for i in range(L):\n",
    "            unormalized = (X12[:,i,:] - X0*sqrt_alphas)/sqrt_one_minus_alphas\n",
    "            projected = unormalized/ np.sqrt(np.sum(unormalized**2)) * r_array[i] #np.sqrt(32*32*3)\n",
    "            X12[:,i,:] = X0*sqrt_alphas + projected*sqrt_one_minus_alphas\n",
    "    \n",
    "        X12 = torch.from_numpy(X12).permute(1,0,2,3,4).float() # first dim is the path\n",
    "        X12 = list(X12)\n",
    "        return X12\n",
    "    tin = torch.ones(x.shape[0]).long() * t\n",
    "    sqrt_alphas = extract(sampler.alpha_bar, tin.to(device), x.shape).detach().cpu().numpy()\n",
    "    sqrt_one_minus_alphas = 1-sqrt_alphas\n",
    "    \n",
    "    X0 = x.detach().cpu().numpy()\n",
    "\n",
    "    Xs = []\n",
    "    for i in range(10): \n",
    "        Xs.append(get_noised(x, t).detach().cpu().numpy())\n",
    "    Xs.append(Xs[0]) # closed-loop\n",
    "\n",
    "    bridge = [torch.from_numpy(Xs[0])]\n",
    "    for i in range(1,11):\n",
    "        bridge += interpolate(X0, Xs[i-1], Xs[i], sqrt_alphas, sqrt_one_minus_alphas)[1:] # avoid duplicate\n",
    "    \n",
    "    return bridge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc58de9b-5c63-4c75-ace7-ec65bfb84d56",
   "metadata": {},
   "source": [
    "## run score calc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3336f615-7abf-4727-b0a2-272ef01b5ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x0, _ = next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cebae999-74dd-4316-a840-664001c6cdc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 1, 32, 32])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3f1163f-b848-4573-aa96-4c3d0a85706e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "normal path: t_in=91, jdx=0, ddpm_iter=999: 100%|| 10/10 [09:32<00:00, 57.26s/it]\n",
      "normal path: t_in=91, jdx=0, ddpm_iter=999: 100%|| 10/10 [06:48<00:00, 40.85s/it]\n",
      "normal path: t_in=91, jdx=0, ddpm_iter=989: 100%|| 10/10 [03:52<00:00, 23.26s/it]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "N_sim = 100\n",
    "skip = 10\n",
    "T = 1000\n",
    "# for method in ['cheapshot_yt']:\n",
    "for method in ['brownian', 'rotation', 'cheapshot_yt']:\n",
    "    # reset data\n",
    "    test_loader = data_generator.cifar10(batch_size=batch_size)\n",
    "\n",
    "    # save variables\n",
    "    int_list = []\n",
    "    d_list = []\n",
    "    \n",
    "    # method = 'mike'\n",
    "    sigma = 0.05\n",
    "    pbar = tqdm.tqdm(range(1, N_sim, skip))\n",
    "    for t_in in pbar:\n",
    "        max_iter = 1\n",
    "        curr_iter = 0\n",
    "        int_list_tmp = []\n",
    "        d_norm_tmp = []\n",
    "    \n",
    "        \n",
    "        for jdx, (x0,_) in enumerate(iter(test_loader)):\n",
    "            if jdx >= max_iter:\n",
    "                break\n",
    "                \n",
    "            x0 = x0.to(device)\n",
    "            x0 = vae.encode(x0).sample().to(device)\n",
    "            \n",
    "            t = torch.ones(batch_size,).long().to(device)*t_in\n",
    "            x0_noised = sampler.q_sample(x0, t)\n",
    "    \n",
    "            if method == 'brownian':\n",
    "                bridge = brownian_bridge(x0_noised, T, 0.05)\n",
    "            elif method == 'rotation':\n",
    "                bridge = mike_periodic_bridge(x0, x0_noised, T)\n",
    "            elif method == 'cheapshot':\n",
    "                bridge = cheapshot_bridge(x0, T, t_in)\n",
    "            elif method == 'cheapshot_yt':\n",
    "                bridge = cheapshot_bridge_yt(x0, t_in, size=16)\n",
    "            else:\n",
    "                raise('You fucked up')\n",
    "    \n",
    "            # NORMAL PATH\n",
    "            # calculate midpoint\n",
    "            bridge_midpoint = []\n",
    "            for i in range(len(bridge)-1):\n",
    "                mid = (bridge[i] + bridge[i+1])/2\n",
    "                bridge_midpoint.append(mid.cpu())\n",
    "        \n",
    "            # get scores\n",
    "            scores = []\n",
    "            t = torch.ones(batch_size,).to(device) * t_in\n",
    "            t = t.long()\n",
    "            for idx, xb in enumerate(bridge_midpoint):\n",
    "                pbar.set_description(f\"normal path: t_in={t_in}, jdx={jdx}, ddpm_iter={idx}\")\n",
    "                pred_n = ldm.network(xb.to(device), t).detach().cpu()\n",
    "                sqrt_alphas = extract(sampler.alpha_bar, t.to(device), x0.shape).detach().cpu()\n",
    "                sqrt_one_minus_alphas = 1-sqrt_alphas\n",
    "                scores.append(-pred_n/sqrt_one_minus_alphas)\n",
    "    \n",
    "            # get directions\n",
    "            dirs = []\n",
    "            for i in range(1, len(bridge)):\n",
    "                dirs.append(bridge[i].cpu()-bridge[i-1].cpu())\n",
    "            # path len\n",
    "                \n",
    "            # integrate\n",
    "            int_res = np.zeros(batch_size)\n",
    "            for s, d in zip(scores, dirs):\n",
    "                # calculate matrix inner prod of a batch\n",
    "                # dxs = torch.einsum('ijkl,ijlm->ijkm', s, d) # <A.T,B>\n",
    "                # norm = torch.vmap(torch.trace)(dxs[:,0,:,:]).numpy().ravel() # trace(<A,B>)\n",
    "    \n",
    "                dxs = s*d\n",
    "                norm = torch.sum(dxs, (1,2,3)).numpy().ravel()\n",
    "                int_res += norm\n",
    "                \n",
    "            d_norm = np.zeros(batch_size)\n",
    "            for i in range(len(dirs)):\n",
    "                for j in range(batch_size):\n",
    "                    d_norm[j] += np.linalg.norm(dirs[i][j])\n",
    "                \n",
    "            int_list_tmp += list(int_res)\n",
    "            d_norm_tmp += list(d_norm)\n",
    "        \n",
    "        int_list.append(int_list_tmp)\n",
    "        d_list.append(d_norm_tmp)\n",
    "\n",
    "    dict_save = {\n",
    "        'int_array': np.array(int_list),\n",
    "        'd_array': np.array(d_list)\n",
    "    }\n",
    "\n",
    "    np.save(f'stats/{method}_walk_ldm_t{N_sim}_untrained_simplified', dict_save)\n",
    "\n",
    "    del dict_save # save some memory \n",
    "        \n",
    "    # int_array = np.array(int_list)\n",
    "    # np.save(f'{method}_normal_walk_t1000', int_array)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d726017-57c2-416d-9a1b-f9676f552bf4",
   "metadata": {},
   "source": [
    "### normal boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8924272-8ada-4c0b-b5d9-d71c1d3a5629",
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'cheapshot_yt'\n",
    "int_array = np.load(f'{method}_ldm_normal_walk_t100.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e2df77-0e72-47c0-bef9-ca6f6d357f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = list(range(1, 100, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548043bf-834b-48ba-a3f7-617a7eab2426",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,5))\n",
    "plt.boxplot(list(int_array[:10]), tick_labels=ind)\n",
    "plt.ylabel('scores integration')\n",
    "plt.xlabel('tk')\n",
    "plt.xticks(rotation=70)\n",
    "plt.title(f\"{method} - latent diffusion\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2605e66-a287-4816-911b-70f698d14e0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diff",
   "language": "python",
   "name": "diff"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
