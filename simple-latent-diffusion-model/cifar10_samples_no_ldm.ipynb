{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a493da9b-2a5c-4e64-8766-170c8b4cf3ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/hpc/share/vuonga2/conda-env/diff/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "\n",
    "import torch\n",
    "\n",
    "from helper.painter import Painter\n",
    "from helper.trainer import Trainer\n",
    "from helper.data_generator import DataGenerator\n",
    "from helper.loader import Loader\n",
    "from helper.cond_encoder import CLIPEncoder\n",
    "\n",
    "from auto_encoder.models.variational_auto_encoder import VariationalAutoEncoder\n",
    "from clip.models.ko_clip import KoCLIPWrapper\n",
    "from diffusion_model.sampler.ddim import DDIM\n",
    "from diffusion_model.models.latent_diffusion_model import DiffusionModel\n",
    "from diffusion_model.network.unet import Unet\n",
    "from diffusion_model.network.unet_wrapper import UnetWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47545d28-10c5-4ef7-8850-9bd6a53238de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from helper.util import extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "328e135f-d501-4720-a448-6bf75ad0193b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "transform = transforms.Compose([transforms.Resize(32), \n",
    "                                transforms.ToTensor()])\n",
    "test_data = datasets.MNIST(root=\"./data\", train=False, transform=transform, download=True)\n",
    "\n",
    "batch_size = 128\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a396e3d-dada-4fa7-8c4d-9973486b8d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the configuration file\n",
    "CONFIG_PATH = './configs/cifar10_config.yaml'\n",
    "\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda')\n",
    "\n",
    "# Instantiate helper classes\n",
    "painter = Painter()\n",
    "loader = Loader()\n",
    "data_generator = DataGenerator()\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "data_loader = data_generator.cifar10(batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8012ef15-6cf9-4b35-b9c6-f8a2181bbd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = DDIM(CONFIG_PATH)  # Initialize the DDIM sampler\n",
    "network = UnetWrapper(Unet, CONFIG_PATH, None)  # Initialize the U-Net network\n",
    "dm = DiffusionModel(network, sampler, [3,32,32])  # Initialize the LDM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0171f5ed-8c4b-41e6-8884-9c976986f06f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 637\n",
      "Training step: 31213\n",
      "Best loss: 0.019144199332412407\n",
      "Batch size: 1024\n",
      "Number of batches: 49\n",
      "===Model loaded!===\n"
     ]
    }
   ],
   "source": [
    "dm = loader.model_load('models/cifar10/dm', dm, is_ema=True)\n",
    "# dm = loader.model_load('dm', dm, is_ema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81eb18c3-50ac-48a4-a126-c9e01f1a0b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:00, 81.57it/s] \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAn4AAAJ8CAYAAABgGKxrAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjUsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvWftoOwAAAAlwSFlzAAAPYQAAD2EBqD+naQAAUCVJREFUeJzt3cnPdVl25/V1+nvv075tvNFHZmTaZVe6bJftLBsblRCjGtSfgBihkijBHAlGCP4AZkwZIqRCVVIhJEQhSq5GNjautEmnMyObiMho3+Zp772n25tB1nj9lkUIyNzfz/Qs7dPtvc967uD3VDnnbAAAAPiFV/9/fQEAAAD4fweNHwAAQCFo/AAAAApB4wcAAFAIGj8AAIBC0PgBAAAUgsYPAACgEDR+AAAAhaDxAwAAKEQbLfxv/9H/IWvyoXGPN90ix1iWpC+m3uiSdHCPz4E7T9Moa5qke+ck/jlKskqOUS2rrFmTfnZr7V/vEhgjJ/3PXlIvS2yZZ/d4da+fS6onWTMGnt3dwa9Jq77nZT3KmjpwLeqOUhN4z4EJPiW9HrvFfwf1oN9RNv3s/rv/+j+UNb8I/qv/+D+QNW3nv7vc6H1prfQeua0D/7Sp8veLXafP02/0XFyOeh0vi38tZ2cn+lrOO32eSV9vZ/4a9L+E//Y8TWB/y/4eaWbWV/49tbXec3LWe8o+63Hmo//dzat+MmoMM7Np1M9lc3rqHh8CbynQjVhq9XwZR/+exr3+dgzbnaz5B//lfyNrzPjFDwAAoBg0fgAAAIWg8QMAACgEjR8AAEAhaPwAAAAKQeMHAABQCBo/AACAQtD4AQAAFCIc4FybDr7MWz9YNM2BPjNtZclS67DDLvvhjNWkwyjbepA1qdUhuM3oB6VWtQ7yXLIOSm16HYJqIixahYGamR1mHfzaV4GwbhEmXZ3pMcZZR2x2i76n861fcxMIFd1WgfdY6fm9NX8d5cD9LCkQ/BqYu6MIJ+30LZvI6S7KGljrfe8/800TCI1POpw2RwKcxTyqst5zhq2e83kO7KNbf8+eJ/1dmK5kiZ1sAxP26L+Du01gLz7o91hlfU+N+ocGgeDfahsIrT7oe5pX/12nfCXHWCP7aBuY3yKUuun1vKx7/Y6WUfcSdSPWdGCNVCLY/a+DX/wAAAAKQeMHAABQCBo/AACAQtD4AQAAFILGDwAAoBA0fgAAAIWg8QMAAChEOBgmkgvVmJ8LtVaB7J3BzzAzM2sCMUtz62cBtZPueSfT+TzVeiJrUiVy2dpAnlYO5OI1Ot+tFbdUVfqe+06/xxTI17PFz4VqUiDnys5lTd/ey5rDwb+n3aCzpQ6jzlpcVj15a5HZuLa3coyq1XOhWvU95ezXrEnP3WXV86UUu1bP6brx1+Bx1HOoqfX6qxs9X0+3p+7x/VG///2XN7JmJ/ZrM7NG5MCmRd9zWvS13E06Uy3Vfq7nehfIyFz0vrQbHsqaVexN/aCvJb0IfOu6QF5dL8Y4iAIzy52eU6voNczM1sV/Lmmr1+I663teVp3xehTrpOsDPUAgGzeKX/wAAAAKQeMHAABQCBo/AACAQtD4AQAAFILGDwAAoBA0fgAAAIWg8QMAACgEjR8AAEAhwgHOVQ6E9tYiELTTp0uVDuHUkclmBxGYmLY6MLG5G2RNW+vA6Wnwn1296muZ68Cryn4gsplZLd7jGMhdbmZ9nq7WwZfW+SHD0xJI6h4D4ZmRbMzs/w1UpUDAbA6E5raBEM5a3Peq/17LcyCcORBUuxPXuwz64bbhXeYXXxX4U3s6iPUVWKTXR712pvGlrHn4+Il7/BgIJL+/0UHF51s9F9uNv1+cngaCl7Per7e1fklp9q/l+qj3yPGo3+Pls8eyZtP6e/r9qq9lDYRJ10dZYpvB3/fnXgfLN4FQ+P6o99GqEQHOWW9M46hvegmsNav8mrTqazkE7jmKX/wAAAAKQeMHAABQCBo/AACAQtD4AQAAFILGDwAAoBA0fgAAAIWg8QMAACgEjR8AAEAhwtGqba2DcivzgySXpIMkd4EA57tAwGYnApqrwK3XOx1CvDS9rBnUPS06sHKo9LXMs34u93v/WoZOjzHVOkhSZGeamdmaRfBl0nOhG/SJ6kXf07Koc+kA8ymwmoakQ8GryZ8Pq85AtRwI855b/ezmyq/Jy06O0ar3XJDnn/xU1lyLx3Wa9X6xbPUaXe71HHk1+wG2F48v5Bjnb53JmrzouXjz/No9viS9Ri/6wD8R2Ih/RGBmo9qPGz3Gg0u9F2xa/X3J4tFtK71hpOpU1syVDr9OIi0/B0Lu50CA8yEQHF41/jvarJF/SiFLbHd5rotEyHY16bVoR92DRfGLHwAAQCFo/AAAAApB4wcAAFAIGj8AAIBC0PgBAAAUgsYPAACgEDR+AAAAhaDxAwAAKEQ4wLnOJ7Imi5DnxnQIcbPosMlN4KpVBOQaCPtsAzXDooMX140fWpn6QFD0QYd9ptYPWzUz6079J7McdMBmswYCkQN/UnTpzj1edfqe7ajnyyhCiM3M0qkfeNvv9aVYrSfmnPS1tFv/HdzX+h2lrINfu1rPu1YETucucC2BwPVSvDroENbTzp9H9XYrx3h29kjWbF7XIcOHV/fu8bONfrePLh/ImqrRe+2nIrP39j4QcHuqr6UZAwHZR/+5NJXeu7pKh59XrQ4q7lt/nM70e76zK1mzHvRzybM/N6s+ELg/629qHXjX2fxvw1xF9iX9Te17HX7d1f783tf6PW8D7zGKHRkAAKAQNH4AAACFoPEDAAAoBI0fAABAIWj8AAAACkHjBwAAUAgaPwAAgEKEc/xSH8iry36mV150tlju/Tw1M7PuGMiRa/2axvR5joPOLaoWna3Trf65qlFfSx14LrV+RdaKHLn9SSCr6RjIf1t0vtthFllXgfy3KpBFt+l1RtI6+nNzDGT0dZvAeWZ9T2P2X2Sb9JxrA5FPTSAvaxQ5YptG53veBrIuS/Hb3/p1WTOIrLNuG8iI63Qu3kbkv5mZ3T3189I++Oi5HOP2p1ey5hvvvSFrLs/9bMKb5XM5xg8/1DUPT85lzfmFn9223ehv3dPXzmRNd65r0urvTZ9/+bEc4zt/+key5tHpU1nzS9/6Vfd41+jMO9vrjL41EPFqi7+OBtODTJPO8fvy1QtZU1X+hjze+5m2ZmZdIDMzil/8AAAACkHjBwAAUAgaPwAAgELQ+AEAABSCxg8AAKAQNH4AAACFoPEDAAAoBI0fAABAIcIBzn32wxDNzJbZDylsBx1CnJK+pNzrfnWu/GDf7RIIITYdgjo0epyU/RDc406HHdd3umbZ6OvNBxGmO+n3nAKBvCkQIFuLkOd11c+2yZ2smY56TvWVfy3LqoOt20o/u7bRNfXiB+u2KRCO3eqadQjMb/OvtxLh5GZmuy6QJl2IeruVNW3r1wxNYD6f6Jqh1Wvn7NET93i7eyDH+O73fyhrPvjhF7LmwbkfFj6+0mG7Lz/9SNZ8POkg9jefvekef//9d+QYH/5Yh/Z+/PJG1tg4uoevD3s5xM3nn8qa9TW9779z9cw9/uB1vReselra8pkOeR7v/TVws9F7ejroudB0+jtVrf44ObCmqzrwYIL4xQ8AAKAQNH4AAACFoPEDAAAoBI0fAABAIWj8AAAACkHjBwAAUAgaPwAAgELQ+AEAABQiHODc1DrstWv8kMK5DoTXNjqksKp1OO3p7AfLLr0OUq0rHQi6Tr0ep/YDHutJB0DWgbDVZtLXm1a/12+zDrVcWz1t0sEPFTUz23T+fNgHwplTIOQ5EppsomY76DHWWc+ptdOBoIP4c2zqAoHflV6vvX7VtohA72Gj/3ZM+hUVo5518Kwlf47cznounq56LjaXfiCymdly41/LgxMd4Pzwoa75l//yD2VNvvev5eVRBwxPdzrMeNj4AepmZlcv/GDl76wfyDG++OgzXXPzUtacbP332Ir5ZGZ2+fhc1lzsLmTNUQQe36yR4GW9v82TrlG58Zusv1F2rudC3+o9cH/0n8sqQrjNzNIY+I4F8YsfAABAIWj8AAAACkHjBwAAUAgaPwAAgELQ+AEAABSCxg8AAKAQNH4AAACFoPEDAAAoRDjAuWp1Cutx9QMGN6sOlR11iTVZ96tL619LI8KmzcyaJRAm3fpB0WZm0+LfVN8OcowcSMHN4vmbmdU7/56WUQds7ve6Zmj0Pa2rn7C5Vq/0eVodVJsanVQ8i8ebFz3nuhMdKtqnQED27M+XTaeX7WR6vvRJv6O08UNxl0kv2KoObzO/8IZKB8J2p/5cW/Z6DtXDmazZz3q+/us//hP3+Ivn9/o8ez0Xr17cyZp58c91CIT6Hk3v+6fHwBpN/r6fn38pxzisgTD3VodsN2Idr71eo8dR72+vvfuurDl/8tg9viz62Qb+h4Cd7ALh49mfD30lEp7NrBsCe1fW8/v+yp8v0xL4dqyBwOkgfvEDAAAoBI0fAABAIWj8AAAACkHjBwAAUAgaPwAAgELQ+AEAABSCxg8AAKAQ4YCtQFydVWK0etIBPe2gs+jWdJQ1XRbjJJ2hlLJ+PEulM5J6kRl4DORPNbXu0ddALluT/SygFPhboEo63zBwKTbkvXu8HfUgVaufXRXIhapXf4Kvnc5qSneBXKhez28R42dr4Pm3XS9rVvMz+szMlqM/Tg48F1sCm0ch5t2prGlF7uHuQk/ozUM/T83M7MMPPpU1f/Sd7/vnOdV5au890NcyHfVa/+TljXv8cK/zRcdR7xf3pp/v9sTfRyP5rlUg17ZpAjmxIlc1ZX2ex790KWveff9rsqYR2Xl313rP6Xr9DXp1rZ/LphI1G/1c7q90lmza6DV9NH++5KPuR9aTr+53On7xAwAAKASNHwAAQCFo/AAAAApB4wcAAFAIGj8AAIBC0PgBAAAUgsYPAACgEDR+AAAAhQgHOC9Z94i59sNcU63Da6ujDuFcKx1gu0l+kOTc6FuvWh3wWM06SDJXfjhp1+pQy1kEL5uZNbW+llW8gzTqQN5l0mGTbaef7yxyUtta33OVz2SNBYKKrfHndzVHgkf1aQ6zXgN26j/f3bzVY9T6HY29Ds3te39OzYFA3JM2vM38whtOL2RN1/pz8eJCv//jvQ4h/uDTD2TNxeMH7vE/+Nu/I8d4+/Unsubjv/qBrPmn/9P/4h5/edDB/m2vF+lu0Htgp34zOei9Kzc7WdPU+nrPL/yab779thzjt//g12VNu9HX0iz+fjAEgq0/++lHsubV4YWsOe/9b8OF+o8TZpYDfU8363c9iI/dbaPnXBWY31H84gcAAFAIGj8AAIBC0PgBAAAUgsYPAACgEDR+AAAAhaDxAwAAKASNHwAAQCFo/AAAAAoRD3AOhCarzNhsOoBwNR0SuSYd8jyt/vWmTve8zaxDcFedk2pZBAjnST+XutHBvyoQ2cws3fvXsh9v5RiH472sqdoTXXMiAoQnPefG/kbWbMaNrLHaDx6dOj1GGwjQHlodeDwf/GDXtNXnSabPU8+REHP/HfS9fkf7RYeTluL1tx7Lmrz47+X69rkc48ff04HIX/zox7Lmd/7m++7x3/+NX5Fj7PpTWfMr770ma77xLf9afvAX35Nj/OUHH8qaFy/1813u79zjdaNDq3/5135Z1rz57GuyZrfzv2XPnrwux3jwQAfhf3H1paxZFv87dcj6W1ct+h8nzLc6UP/uZO+fp9YfzCkQ8tz5pzEzs1H804MUCPw+rHpPj+IXPwAAgELQ+AEAABSCxg8AAKAQNH4AAACFoPEDAAAoBI0fAABAIWj8AAAACkHjBwAAUIhwgHPV6tDkWeQu5qSDZ6tRX9Iw6BoVdZhGHd7Y9Do0uV11OO2Y/fDGtdZjNCLU1cwsB9r4pfLv+27UwZjW6JrpqIN9t71/wfOqQy3zrQ77XE78sFUzs7T6weF9u9XXUgWud9LjLLUfctpFQkUDgdNzIA902/hrds56jWzEGCWpA4nvx+sr9/iH3/m+HOOz5z+SNe9/TYcD//Y3ftU9/vTxAzlGlQMB6ls/tNzM7G+e+6Hw77/1hhzjNz/TIcR/+uf/p6z58sefuMe7Cx1a/Ru/+Vuy5slDHb5sG38PrPUStbt7HYR/faf/oUGV/E3l9PxCjvH+H3xT1rz2qZ67P/nwA/d4m/UGmJNer2PkHz00/rfh0ame/3YSqAniFz8AAIBC0PgBAAAUgsYPAACgEDR+AAAAhaDxAwAAKASNHwAAQCFo/AAAAAoRzvFrRp01l0XJHMjFq7aBXLyD7leb2s8O6ys9xnjUGT7toDN8mtXPWUqBPKHU6yy0edKZdtb6NZte5+/Ns86ia7N+dtNeHG90dmQW92Nm1prOPxoafz4sk87oS42e33Wl50tX+9fSiGs1M+sDeXHWBIL8RO5jNeh77vaBHLdCfO+P/rWsOSR/DzwcXskxnpxcyppv/dJbsubNyyfu8XkK7H+RaRb5vsx+fuhtfS/HeBjIHfzd3/i2rHn+5qfu8Waj99H+4bmsyUmv9dPWzzc8BvbIrenvy9mJvhZ1qmdv6hy/B6/peWntIEty9udL0wTe0U63SHd7PXc/+OiH7vF21ec5vdTZkFH84gcAAFAIGj8AAIBC0PgBAAAUgsYPAACgEDR+AAAAhaDxAwAAKASNHwAAQCFo/AAAAAoRDnC2ppcllRitDwQVz3t9SXUgKLer/EDKqdXnabIOJ7291s9lK07VVIFw4KwDK9usQzhl9rXOQLU2i+RlMxs6HZqcN/7z3S76npvmqwm1zOaHReek33PW09JSredd3/rzIY+BuXuiw0l3q77gQ+Unsu6ql3KM+04/u1Lc3n4ma4bGXzuRIN3LTtdst7omr8/d4+OdHx5sZjY0umacjrImJX9dLCLg2czsNjAVU63Dz5+98dQ9PicdmnyY9PdwDLxHq/x1XK86YHiddMj6szceyZpHl35A8zzfyjFefaH3lHnU4f7nF/61nPT6G3V6eSZrAq/RevFtvtrfyDHWWfcJUfziBwAAUAgaPwAAgELQ+AEAABSCxg8AAKAQNH4AAACFoPEDAAAoBI0fAABAIWj8AAAAChEOcM4iJNLMrGv8JMNx3coxmq0O4cxJ96uj+QG27aTHmCL3XOvrvRfPpc467NNmHViZde6oNUc/SLKpdGj1vNXBl0utk1K7JEKGI6HhtX5HS9LvqF78axkXHTA71Hp+t61+SSr8te70O6p7HZpbr/q5DJ0/d6tVn6cdAgmnpdjrdXzs/Pc/ja/kGN2JXjt39zqctpn8+VoNOsx9OtXvvxZ7pJnZTgQrp43eC6YxsF+0+ttwEGu0Nx0+Xwc27DWwX5j5+8Gk85stJ/38u8A/Pdh0fs39Xgc4f/bRR7LmfKvn90nvv4Ou1v/wIC13sqZbdVj+m8+euMff27wrx3h55Yep/3Xwix8AAEAhaPwAAAAKQeMHAABQCBo/AACAQtD4AQAAFILGDwAAoBA0fgAAAIWg8QMAAChEOMA5Et64VqN7vAnkFOdJnyflSMizGKPVqZbt0b8fM7O10QGb/egHRc6mH0wVCNhcsu7j58m/p1zr57K/1wHCu3Mdarlp/TDVKZA8OgZCiFsR5m1mNlV+sO646mupZx3yPNY62NXMv5bBNnKEbtbPxTo9X5KYm02t71nHfZcjrTpA+KMvvu8eP9zp0OT89IGsaU/1m6kf+O9/HfW6yHfXsubp7rGsWS79dVyZ3os3jQ7tPVZ6nKX15/246LVVbQLrbw6En/d+zabR39Rjra/l7uZTWTMu/ruujzoQ+bzT7yjrT5A14r4Py70cY10D/0TAdJ8wmr/ut4HPwsM3XtdFQfziBwAAUAgaPwAAgELQ+AEAABSCxg8AAKAQNH4AAACFoPEDAAAoBI0fAABAIcI5fttA7t0x+1k13RrIR+p1LzoGsnVakZ03BnLO6sD1Jv1YbOr9/Kl10rlFkZqUAuFGIq+p7k7kENX8pb6WKZA72PnvYEz6+deBzK100FlzS/bHCUxLW1r9juyoM9hkCOWJfrbHQF7cJrD6G7Gmc6Oz4Kqsc65K8fEnX8iaH3925R5vciBTstNZjy+OfyVr7t7w10436IzMs5NTWfNgp2uagz+P7o86l63p9f62Dpeypl7Fnh7YiyN7+kZ8O8zMFvPf0SIy5MzMDld6j7yb9fN99sTfD3aD3kizvmWbArmq+1Hdk+4BrlYdsJfu9HM5rv67Pt69kGOcDk9lTRS/+AEAABSCxg8AAKAQNH4AAACFoPEDAAAoBI0fAABAIWj8AAAACkHjBwAAUAgaPwAAgEKEA5znTqcqJpXT2ujztL0Om2xmHY55P/o9bdsGzlPrCz5MOryxm/xx1qRDfddAYOUSaOPzwR8nmw4V7bIOQU2BaxknPzQ5EoLadvo9joMO6pz3/rUEpoJVs77pqtHX0oj50raBUNdGv8ex1Te1nfzr3Wd9z20gCL0U3/3wY1lzK8Lnz0QIu5nZj774RNbUgb/7n1/f+AX3eox/7+/+lqzZ7baypp1v3eOfPdfB8jeTfi4Pnr0ha/raD8ie93qdH5aDrKkavdZX8W0e73WYt2Xxns2sqnVY+3LjtxRXnd6X6sCHrOsC3+bkv4Ml6zE2kz/nzMxuA9+pWnxfDq3eI1+9+lDW/J6s+LfXE6wDAADAzzkaPwAAgELQ+AEAABSCxg8AAKAQNH4AAACFoPEDAAAoBI0fAABAIWj8AAAAChEOcO7SIGvq2g8HbrMOKZyqXtbkrEMt294PXjzN+jzW6Jq7u6OsOR78gOZpCoRaWpI1fSBkeBE50G2j/xbIGx2anJK+3nz0AzZTYL6M+lJsPernq653E8ggbmsdbN3udJhqVjmpnV6LfeD5b9dIELS/BraBcOZ10NdSis+/0PtFavxg3zHw/mu10M0sJb14rm/8tTO0er/47POXsubXf02HGe9O/bmYkp6LN3c6qLh9oZ9vEuHz9U6vrSbwu8t0r/euavW/ddOix5hFILWZ2ZOHssQO+zv/PEe9F3RbHeZtla7Jqz+npsA3td3oFmkz67k7Jn891qPuNaqvMAifX/wAAAAKQeMHAABQCBo/AACAQtD4AQAAFILGDwAAoBA0fgAAAIWg8QMAACgEjR8AAEAhwgHO+/srWZM3fh+Zsw4MzVfXsmZcZlkzHf2acaPTjqvlXta0jQ5knWo/KHI/+wGcZmZNowM2+0D48uZM1FR6jGqUJdYExjkc/Jq20iG04ytdM2c/KNrMzEQe6NA/kkM0gXDmttLzrhUllQXuZxMIODW9HjuxZsdOh4ouc3ib+YX3xhvnsmaa/ATvauuH5JqZ5UWfZw2En59u/GDZk11gPgfCgfd7PU4Scy2Q32wPTy5lTdfq8OXnX3zmj5F1mPvThxeyZgms9fnW3wOXWW/Ya+3/kwEzs3l8IGtMXO/xXn+7L7vAvnSmX/aVCB+vb/W1pHMdrLwE1lHd+9c7BP77Qt8Q4AwAAIC/Jho/AACAQtD4AQAAFILGDwAAoBA0fgAAAIWg8QMAACgEjR8AAEAhwgFbc+Vn0f1sMD/QpgnkzDWdzh8bV52/8+rlC/f4T778iRzj04+/kDVdpXOW3nr8xD2+OdEZcanXr6rO+vmuq58F1F0Mcowh+zljZmZd4E+K4aE/pyo/hsnMzOZK50/lva45Xc/8gp3Oc2obPXerRs/dpvYfXmr18zd9GtMJiGa5F++o0ZlnfeREhXjvrYeypl79iX/55BtyjIdP9HmWg15g55d+HuDhcJBj9KPOH1unV7Lm6qW/B76809dyEci3tEnnqj567I9zeqFz/CIuW73vzCLTrgp8u19dXenzbPS3wVb/HfU5sDFl/R4nHWVp9dHP4b16pTN4m0Hvb02la0wsgWrQz6XKgbkbxC9+AAAAhaDxAwAAKASNHwAAQCFo/AAAAApB4wcAAFAIGj8AAIBC0PgBAAAUgsYPAACgEOEA50dnIuDWzHLjBzjPiw4p7PpAYOJGh2Me7x+7x5/OOnh5+fxa1vz4+Zey5sVHP3WPP3r9mRzjl7/1a7Jmc/G6rLE78Q5G/bdAt9MBwrPpEM5OBPtO3SjHuNhuZM3J+VNZ09b+3N32gfDxwPxeAqHUR/H3WB0YpG71/M6dDmRNc+Merw6Be250UGop/v7f/wNZU4vA8dPAXjyNeo68ePFc1txN/jzaPdTr7/CF3guev9R7bXch9p3aD+w1M5uTDjPeVXp/Oznzv1PD2YU+T9Kf30Amv6Xk711nO/1N7ZJOWe86/zxmZmPt7wenjd5zTjensmZt9PxuVz/8Ool/IGBmlld9vV2n3+Oa/DVwd63v5+T0q9tH+cUPAACgEDR+AAAAhaDxAwAAKASNHwAAQCFo/AAAAApB4wcAAFAIGj8AAIBC0PgBAAAUIhzgPPV+GKKZ2bD4gYi16QDIZdXBs82qA0yHJ35P+3YghPj11x7JmouPP5Q1n//oz93jf/7HfybH+OzHOmz17W/qoOKnr73hHn/99bfkGJvWD/U1M2trPV8s+8GiTdJjpFGHtjamA0yt8cOi50mPEchANQsEj+baf77LmuUYVeTZzXqcuvPXY+703471otd9Kb7+/puypl79OTLe6zn//EbXjF/IEru9unKPP35D75EP3tL70hAIGX7w4KF/LRf+cTOzKunvy1rpNdq3fsjwaeD7Ms16w0gHXdNu/HU8BD7zr13qPf1+0EHcm9V/jyfnWznGdqf/QUNvOji8feLvO9Oq96606ue/T/rZreaHsrdJ78UnJ4FvahC/+AEAABSCxg8AAKAQNH4AAACFoPEDAAAoBI0fAABAIWj8AAAACkHjBwAAUAgaPwAAgEKEA5y3yQ9nNjNbB3+4btQhhTkQ8nzb6XHODn4I5CjCHc3MmsMzWfONTod97no/4PGjDz+RY3z/z78ra374iR8UbWb2ztN33eO//bu/J8d44+13ZM3uybmuEUG1lc7FtHEzyJra/HBmM7M0+4Ggy3Irx7gbdAhto6eutdkPOW3qQPBr4G+61Myypjr611L3eoy11ntHKdbZD3I1M2vEHtjqLceGSs+RB090+PLQ+vtoU+tA5Iu3L2XNa6d+sLyZWRLZv+mon+3hqNdoHwj2bRp/nGqrQ4i7PhDEXuvQ5CX74zzo/LBpM7P18RNZcznriZdER9H2+tme1vrbPC16fle1/23YBDbjpdHXK/KzzcysPvgfsxz4hwdn8XZN4hc/AACAQtD4AQAAFILGDwAAoBA0fgAAAIWg8QMAACgEjR8AAEAhaPwAAAAKEQ6G6Xc6VC0tfl7XoiPXbFvpDJ9u1QMdB3+crtE5QMO5vueTnc6fahv/ev/Ot39XjjFe64yqH776XNZ8/vy5e/yf/+H/Lsd48FDnf21FpqOZ2fmDp+7x0wsR3GVmbSDTcTvoTK3NiZ919fzmXo7x7NHbsub8TGdqJRFgeMg6l7CrdC6U5UBeWe+v6anR63WzBK6lELnW+ZZN8t9vbnR23rLofEWb9Ls73fjXewjkzJ1vLmRN2ui9dp79udjZmRyjPdVrZ7oN5E5mv6YK5BvWgey2PAbWTuPn692u+ltn01GW1K2eL+3qP5fW9P3cHfS3I4nnb2bWtP6ePQXm/6bT79FGPe/uRWZtV+nzPA9MBd2N/Ay/+AEAABSCxg8AAKAQNH4AAACFoPEDAAAoBI0fAABAIWj8AAAACkHjBwAAUAgaPwAAgEKEA5xt1QGbTe2HFFamw3YnC6Q8rzqc9OSBf675Xp+nSzr4crN7LGvap/6ze/B7vyXHqGsdWHn7j/9HWbO/9oM6v3z1mRzj5QtdY+1Glpxd/Ng9nir9nu+uAsGjjb6W040/H3aXD+QYf+tXZYktb35D1gyDHzya+k6O0Q56vnSzHmdt/XXUVvpvx6O/LRSlGXVQ62H1n3kd2Jds1OvicK9D4W8Xf5xafxbss89fyprTOz1JHj186B5vA6H866TXxd3hhay52t+4x6dVh9z3Oj/Y0qLX19L6913Peh895kCYcWCtj+ZPiH66k2MEbtnqQC+xzP49pazbn1Xnk9sx6aJahO4fZ33Tqf7qfqfjFz8AAIBC0PgBAAAUgsYPAACgEDR+AAAAhaDxAwAAKASNHwAAQCFo/AAAAApB4wcAAFCIeIDzoAMTk8gMrVodEtmuOsizFoGVZmbzrR8kOQR63qXR91wFQoY39Yl7PJ3p8/zu3/l9WfPihQ5k/Rf//H9zjzcpEPYZCEG9EGGrZmb91n8ux/G5HKPZ6mf33hvvypqnb7/pHn948VSOcXb+hqzRT9fseOOHnPZbvWyPr3Rodbfxg6LNzIbNhXv8bKPXUVPrd1SK67tbWVNX/v423+lw5mMg5P7qoGuef/ZD93gdCJVNR/3+H7/uByKbmTWd//2oRPC1mdndtQ6frwIB2Uvj74HTtb6ftdbPf6p0yHqd/Ocyz354sJlZfdLLmjHpa5lm//u91IFvd9LflzUQeNw2/vNNg77nNXDP2QJJ3CL8eg2853HV4e9R/OIHAABQCBo/AACAQtD4AQAAFILGDwAAoBA0fgAAAIWg8QMAACgEjR8AAEAhaPwAAAAKEQ5wjoRwJj8z2WzVp2sCvWi36ODFaSNCUGcdnrmaDpts9vqeVFBnn/X9pFMd8Pjv/72/J2ve+fp77vHrl9dyjB/+6GNZc3Wlw5eTCOtO66Uc49e+/bdlzd/9vX9X1uTu1L+Wow7PHANzd7/osM959ufddK/XYt28kDUvbg6y5nHlh7/mXgd1Wz3omkIc73WY7iTCadO9XqPVqufiZaM2bLPDVszFG71HHg+vZM3DzbdkzVD58+iwXskxDqMO0E6jfi4nZ+L5BoLlj6PeC+qk54v6/SY3+vuS7/W1HJJ+drn2v4fjovfRY9bf5sgvVt3ef48psP9VG/197/NO1jStuKdVv6NmG4n/j+EXPwAAgELQ+AEAABSCxg8AAKAQNH4AAACFoPEDAAAoBI0fAABAIWj8AAAAChHO8cumc+TS8ege7wedQ9MELmnq/Pw3M7M6+cePSecsLaZrdiKLzsysrv2MpFwH+u9F3JCZ7U4eyJpv/ea3/YJW53L9/o2+559evZQ113d+LlRa7+QYb7/2jqxpxfM3M/vyyj9XpXKYzKyp9BrZBjLtunziHr94pOfC/azXUZU3sqbN/jh3gcytNpAjVoqrW51jlieRL3bU+WNdpfeU3em5rHmvEblsF/dyjM9vdM3LV1/ImmeDvzfVi967TvsLWbOYvt5l9J9v0+h3ZIFvx/W9ni9N4+9vU9a5hG2na7aBvLrD6O+jtQXycyc9d5esn8u8+ueqAr971YG+pwt8M/fZf0fjfq/Pc9T7fhS/+AEAABSCxg8AAKAQNH4AAACFoPEDAAAoBI0fAABAIWj8AAAACkHjBwAAUAgaPwAAgEKEA5yTCIk0M7PVDzI8Ljq8tloC4ZkiVNbMbEh+8GJf6SDJKutgxkMghLOp/EBekZFqZmbrRoc3NrN+Ryr7ep902G5zrsM+39s9lTXzwQ+QTeIdmpktSQel3k5+sLiZ2Xnnz825O5VjVIG5MC762U1qWepccTvr9LM7eRAIVq7VGtAh0FUgbLUUV598rosG/72c7PS7rQNh4kPS72Xt/XFS4P1vFj+o3czsx3/5XVlzc/3YPV7XgXDmKhCgXesN+Tj5gbvdXSAQOema46L3lCn5+3616A0jN6OsCWxv1rX+fKlrved0lf7WTUd9MfPs7/uNWGdmZt1BfzteVfobtBv8HqAPbOr1Ntyu6bG+spEAAADw/2s0fgAAAIWg8QMAACgEjR8AAEAhaPwAAAAKQeMHAABQCBo/AACAQtD4AQAAFKLKOQfiYAEAAPDzjl/8AAAACkHjBwAAUAgaPwAAgELQ+AEAABSCxg8AAKAQNH4AAACFoPEDAAAoBI0fAABAIWj8AAAACkHjBwAAUAgaPwAAgELQ+AEAABSCxg8AAKAQNH4AAACFoPEDAAAoBI0fAABAIWj8AAAACkHjBwAAUAgaPwAAgELQ+AEAABSCxg8AAKAQNH4AAACFoPEDAAAoBI0fAABAIWj8AAAACkHjBwAAUAgaPwAAgELQ+AEAABSCxg8AAKAQNH4AAACFoPEDAAAoBI0fAABAIWj8AAAACkHjBwAAUAgaPwAAgELQ+AEAABSCxg8AAKAQNH4AAACFoPEDAAAoBI0fAABAIWj8AAAACkHjBwAAUAgaPwAAgELQ+AEAABSCxg8AAKAQNH4AAACFoPEDAAAoBI0fAABAIWj8AAAACkHjBwAAUAgaPwAAgELQ+AEAABSCxg8AAKAQNH4AAACFoPEDAAAoRBst/C/+k/9I1nRrI2uG3q/Ju1WO0Sy9rMniPGZmber8gj7JMepq0NfSLLKmS/p619Xv01N7lGPUi37lTR34e6Cu/OOTvufF9D3XpufDXOnrVSVtynKMvNnJmq0F7nuj30GVxH1X+tkto76WtjmRNauN/vFGzAUza4/6nv/hf/6fyZqfd//rP/5HsmZt9P62q/znWZ+Ivc3MOtPnqQa9turVP1ddzXKMfeDbsdvq621WvWcPYrrmWj+7ZbmRNWZbWTGu/rOp1cWaWZf1O8qNvqc68Oxm8VtRJb5RP7sYXWKN3venyEBqbnZ7OUQ7T7ImBd51zgf3eBfoJe5Xvad/+w/+HVnDL34AAACFoPEDAAAoBI0fAABAIWj8AAAACkHjBwAAUAgaPwAAgELQ+AEAABSCxg8AAKAQ4QDnk0BI5BgYbV78cbpZh0imWod9doFsRxWN2Y56kK7T4Y570+GZTR0Ii279+x5rHXDaB95Ru+j7PoqSehsI8076YtZASOeQdU3binMt+noDl2ttYEmtSa+lrvLnzBqY332ti1KlA0FNBG13gXVS6alZhA9/+H1Z01WBMHFRMvd6jg3NRtakwG8DnfnjzDqL18aj3kf7cx02fhYIR88iZLhudBB+1ejA3k2vb3wRC7kPnCcFvs1r64ewm5k1gXfdVP5XM7eBMPfAllNFQuEDIfZZ7DtLIFjeAiHPaT7V46hXuepQ8LzokOcIfvEDAAAoBI0fAABAIWj8AAAACkHjBwAAUAgaPwAAgELQ+AEAABSCxg8AAKAQ4Ry/cRPImTvocRqRz1PlQEbfGggC2uq8my75GUqRhLO86oy+etUZVXMgc62q/T69n2Z9La2+Fut16Nom+1NnXvUYKZDD1AfyDZdZZz4ttf82+15fS9vqv5PSqrO7ukA2V5/9dzl3+jxz1udpap3vVc3+u171aaxL+j2W4PJCr4su651nFll0lgLheZV+97U6j5nNlT9X60Duaj/o670/Xsmal4FctloEcg4WyJIN5CTeBz6vMjuv/1KOkedAXmfeyZqq0fNO3XYlcv7MzCaxt5mZdTJl1yy1ei1Vyf/eVZPOspxM5zqugezNtfMfXiuyW83MlsCeHsEvfgAAAIWg8QMAACgEjR8AAEAhaPwAAAAKQeMHAABQCBo/AACAQtD4AQAAFILGDwAAoBDhAOdqr0M4514nOLfZD2Zcl0h4pg5ubEYdqNiKkNN60CHQaQjc86JDIpdFh2fmSZzrqANZc3Mva+wYCPt8cOoe70RIqplZDgRxL42ed0lnfVq1+uO0Sf8NtCyBUNyNvu9q1IGg+9ZfB03Sz2UJrIGh0fe0tH5Nt9f3PHf6WkrQBgJuu1rX1OKRV0nvOWvay5qm0+O0Igg/B8LG61HvtRf6UmycA4H6aipWOuR+WfV87gKh1Mvk7zs56ftZA1/xKhAwbJXej5vaf09LDjwXEf5vZtYEAvVzILi/bcSk6fU7iuy1VSB0vRXPJpD9b1sL/AOGAH7xAwAAKASNHwAAQCFo/AAAAApB4wcAAFAIGj8AAIBC0PgBAAAUgsYPAACgEDR+AAAAhQgHOE9JBwe2h0AIbu+HGKq8RTOzNetAxSYHgqA7Pxxzqmc5Rj/rsOMx8Oz6QPDlF0f/es5XHSZ9Mt7KmsN6JWtsedc9PJ/oNMqNeP5mZvOkgzFlmq2ZdSKrdjrV77pZ9PVaIDR5afX83dQi2PUYCCgPhJPWnV6z/dG/7+NGr7UuEMxegiGwF0yBR1WLFOIcCObuGr1uVtPrwkTgdJ71Da2mQ83TQa+bvtbPt+v9j8ySAv8gIBCk2wVCtKutCCEOfBfavQ7utxP9Dpakv2XN6o8zVvpa6qzDunPS+35dBfoAlfEs07xjYdJtpefMNPpr8mwXCG4/CTRIAfziBwAAUAgaPwAAgELQ+AEAABSCxg8AAKAQNH4AAACFoPEDAAAoBI0fAABAIWj8AAAAChEOcDbToYuTiZRcM9up0MVJhxj2jQ4VzV0gUFGEUVaz7ovzeSCwd9T3lJO+p7T459qcnsoxzgPB1vc/+ljWTM0L93jbXsoxRnE/ZmZZJnCaVYMOq61qP4R4SYHzBEJxm0C4eFcFwsUPIqB3o6+lnfU9rZN+B7MIMu8C68Q6ApzNzJZA6GxeA+9NzKFe7G1mZqsF9q5KX0ub/Zo1Ba5lDASJZz3nj1u9jy4iSDc3+ttRTYFvQyBAfTn4NZutvpa01cHyVSCHe6j09apM6vNpK8dYNvpiqkbfUwrM8arx+5ZkgX8QMAZqAq3UwzP/2ayVnlPHRj/fCH7xAwAAKASNHwAAQCFo/AAAAApB4wcAAFAIGj8AAIBC0PgBAAAUgsYPAACgEOEcv3U9yJrc6j5yEjly3aovqd7obCmbdfZO1YrcojWQj3S8lzW75kTWjLV+dl3n3/eYAzlAWWco1YH3OI9inNNJj5F0jtim1vmRdWDOrJV/rjqQy1Wd6pyrIfB8x8CyyyK+a1wCuYOLvt5Ivl5V+9lz06LX2hDIsizBNOscv1asczOztPrzeQrkBVa1Xn+pCcyPyZ+sg5g/ZmapP+oaC8znVp9rFpmp28BppqT3i9TodbEs/l5wGG/0GFlnu/Wm96VVZJ2amc0ib7FJet9vAvmR+TDqGgvsKeu1P0arcxIDcYFW9/pdr+aHIHanD+UY3/3xJ/piAvjFDwAAoBA0fgAAAIWg8QMAACgEjR8AAEAhaPwAAAAKQeMHAABQCBo/AACAQtD4AQAAFCIc4FwlXdoE8hTrLIp0hqStq07YbHIgJDf7YZ99rW/oOOuadtWhlovplMi58fv03Ovw0mXcyZrT178ua7refwd3o37+VeD5jqsO8twmPR/WrT+x+kkHcNp6KkvGQCh11iV2rPzrqcdAsG5gPY4iCNjMLDd+uG6d9Lw7BALVS9CtOkg3BQKcs9hHc6PfaySovZn0OFPl72/Lqs+zDXxfjiKE3cysm/Szq1c/8PiQ9Z6Tav0PDdqjDlbulr17fJ70tVSBa5kDweFTHwiFF/9oYA0s88UCIea9vm8LzPFZfOMtEBTdbfQ/ERinO1mTGn/tf/JXn8kx/uk/+Wey5h/+g/9U1vCLHwAAQCFo/AAAAApB4wcAAFAIGj8AAIBC0PgBAAAUgsYPAACgEDR+AAAAhaDxAwAAKEQ4wDn3OjB2DYTXWuufsq0C4ZmjTnmuOn29rQiCXi0QghoIo5ySDsacJn29g0jIzoEwynqnwygvAkGe4+yPc3+4l2PkQLBrU0XetU4N3cz+OIvpEGg7BuZmr5/vNAbCSVd/PsyDfi4id9nMzOreD5A1M1uP/nuqW/3sUiS1ugDJdIDzOurA99z5778VIcVmZksgnDlP+lqqyp8fqdXnOUx6H7WNHmcJBL5XqziXCKQ2M6uT3rsq02urFsHy3dzLMdZVBzhPgX+MsIn804PkP9+21fufRQKy7/V9V9tAGPrqf8uqpB/Muuh5N0YC9UX49Y9++LEco2/0uo7gFz8AAIBC0PgBAAAUgsYPAACgEDR+AAAAhaDxAwAAKASNHwAAQCFo/AAAAApB4wcAAFCIcIBzm3RAYRbhzGZmXfYDFVPeyDGGTgcM50qH+i4imHEJhM72jQ6aPIx6nNQEAqdFWHQfCA9uW/1c5sCfAzc3r9zj1198Ksd4/OxtWVM3+p4Oo04qvr699c/T6fd4fqqfXeQvKZEpamZmVfJDZNsxEJosQqDNzKpITe3P33HRd1134a3mF9oSyCluRz0Xrfbf/6bXz/tuvZI1gUxfmzo/VLYOhNOvWx343h31XpBbfa5FBE7Xjb7pedXhwVUgIDupPX3R55lNfzOt1UHFUxXZU/y5mWZ9vW3gWuZGz4dU6XXSzv58yJtAWHrgH1NUkTkjQp77QJj0L339HVkTwS9+AAAAhaDxAwAAKASNHwAAQCFo/AAAAApB4wcAAFAIGj8AAIBC0PgBAAAUIhyuFYgNs6rVAWVr9nNzhlkHXR0qfdlVICstpTtxXOfq5FHnDTWNzlkSj+Vn42z83KLdoK+37nX2Ub2Msub63n92z2/0c9kEsrt2W/23yTjrHL9p8TP42qzzv8aDLLE6RRaKn3tmZjaLvMW06OvtREaYmVl71AtlFhl8TdbvKM86C6sEzaznR271+pvv/HfbPNbnefzwXNZcHfS1pOyfq9HRbjYd9Byae73O6yqQhyqCNI+BjL77wHPZZL3+mtnfVKZA/uXc6LU1jPpaVpGxa2Y2Nf6+tDb6PbaBXNtIJnA+BD6aJvZRkUtoZrat9X79zWdPZc2ffOcH7vF6/1KO8e7bX5c1EfziBwAAUAgaPwAAgELQ+AEAABSCxg8AAKAQNH4AAACFoPEDAAAoBI0fAABAIWj8AAAAChEOcO7qQCLyogMVc+OPs1gg3DHpJN1l0WGfa/YDj4dlL8eYa/0Ij4MOU+3XSFCnX5PWQGBv4PnuJx1gOopgzP0L/Y6+8/IvZc3Z5lTWPH79HVlzcemHaE9H/37MzA4pEJosgqLNzMZ0K2v6JObDqufUGAgOT42+p2X176mpBznGHLjeEry8/ULWtGKdm5k1w4l7fNfrveDk0h/DzOz5rV7H492Ve7xaAiHsgU9RnvTaioQQ942//uZJX0sn9j8zszGwtkyErNdi7ZmZVaN+vutOX0ud9X2vsx9mXJs+zz7wrct667JNIPR7bf3nezJcyDGeXOhv0HLU931zde0erwJB3IflqwnC5xc/AACAQtD4AQAAFILGDwAAoBA0fgAAAIWg8QMAACgEjR8AAEAhaPwAAAAKQeMHAABQiHCA85J1IHIjwh3NzNLWD3KtKh0enA+jPk/WYdJt8sdZBp0i2QSCPKtRhy5WvX52/ew/m3bV72jb6NDW63sdMLx/deMePy46sPeLz+9kzdVj/XxPHjyTNbX5IcNLpf8G6md9T2kKBCLrbF2bZ3+cXgSTmpnVgbm5iBBzM7Nc+fN3afRa0yu2EHUvS9pWb8vnO/+9nZ3odf74zb8la672/5esub3310Wn872tMx28POVACHEgiH1RgdKDvpZx0c936PQalXcU2CtyYEM5HvX+tgz625tEy7CM+vnnQLB1f6uv99jr/Th3/vU+ffRQjvHixStZ88/+538la5bJ/64+++WvyzG2u8BiCuAXPwAAgELQ+AEAABSCxg8AAKAQNH4AAACFoPEDAAAoBI0fAABAIWj8AAAACkHjBwAAUIh4gHMghHiqdYBwNfrhmN0SCYDU17JMOtSyqv1zdZOOnV0qHchabQJhu63uwWcRbj03OtDysAae76IDeV+98sOXD8e9HKO6CIQH60xRu9nfy5rxU/++216f6Njr5XLRnMmaptXB4Gvrv4McCF5e6kAAeWAttat/LWPSz6Vd9TopwVDpANah1u/Ejv6eUgWCdCNh0r/8S78pa56+8b57vFn02lqTvufc6ntKiw5fnvf+uaasA+yrrNeWBe6pavx7WrO+nzbpQORD0s+uDbQDx9nfC5bAN7Mb9N6VZn3fS6XvqRbp4a+/8Zoc45NJ9zXj6v9DAzOzvfg8v1XrdTIermVNBL/4AQAAFILGDwAAoBA0fgAAAIWg8QMAACgEjR8AAEAhaPwAAAAKQeMHAABQiHCOXwrk81il+8i08bN38hLI+AmEu1WBDKXDwb+ntdOPZ151hlK60zlAw4NAnlrjZ3flWV/Lftb5emMgO+p+9M+1v9PvaArkDk5Zz7v7m89lTdU9cY+PSc/d5qDvqZ++lDX2aCdLuhM/J6wKZL31tc43bAN5ZMfafzZ50s8lW2D/KMBa6ef99PW3AuP4a/R21WsrENdp91OgqPL3gjnpHFPTW45Zo4u2G/39ODnd+gW1v1eYmfU5kIvX6+utzL8W/RbNxlZXnVogS3bQuY7N4u8FYxvYCwIRk13gu3pIBz2O+fe0udS5mu+di/liZn/j69+UNd//8XP3+F/92R/LMaoh8PAC+MUPAACgEDR+AAAAhaDxAwAAKASNHwAAQCFo/AAAAApB4wcAAFAIGj8AAIBC0PgBAAAUIhzgPCcdHNi0uo/MRz9sck46jLJddXhtCgTcziIIOumsY7uedUjuOOoQ1GGnAzZ32zP3+HwMXPCswyivb3XgtImw6M2pDlJta33P416HdN7tdTjwMPjjdI2+3tvlWtaslQ5BPT/oZdcM/vUsgbD0LhCQvebAu179INpc6ffYV3o9lmCz1QHO529+TdY8efiae7zr9DtpTnTN/ioQVNz5c3Ve9BiLCNM3MzsGpmrV63m2rfy94HYMhI2ver+Yb3WA89peucenrPeKNumw45eBvTbXeu/qxP7W1PpapkBNG+g3Ij1JvfrX+zLwfclH/Y1fsx7n09tP3eOf39zIMS7rS1kTwS9+AAAAhaDxAwAAKASNHwAAQCFo/AAAAApB4wcAAFAIGj8AAIBC0PgBAAAUgsYPAACgEOEA5zrpEOJ10cN1qx/e2ASuaDrqgM3UBXravX8tzw86sHd/r1NFA1mfNgdCiM8u/ADn5kQ/vP2dDqNMsw5BffL0qXv8YX4mxxC5wGZmdn+rQy3r7U7WbGv/JaRW33N1PJE1p50O6H3t2SNZU2c/cLVadAhqzrrmMOt1klY/CDrr3Fc7mr6WEvzk+x/Lmg9+6ge9mpl97e333eOPX7uUY/Stnqu5DYTtzv634Zj12jqpBlnTVHp/S4Fw4OvsB//e3PvB/mZm28g/Kxj0fd/v/XPNgXBmm/R56qzf9aCz/a1J/r507PWm3q06THrZ6HGaUQfU78V/YdgHvru3r76QNT/96CNZ85OffukeP7/U35cqELoewS9+AAAAhaDxAwAAKASNHwAAQCFo/AAAAApB4wcAAFAIGj8AAIBC0PgBAAAUgsYPAACgEOEA53nUoZZd0jVT66e9tlmPESixOfvBjWZmU/Zv/zge5Bjj7IeBmplVkw6jHO91QPZ+8QMrqxt9nv1RBzjfzYEHXPmByG3W4ZpXk36+RxH4bWb29ORU1nS1/zdOlXWQ58XZQ1mz63UKamM68fh+8oOr86Lf9abSoa1NowPIc+u/68r0fDmKoNpSpE6H7f70RzoM9t/8yZ+5x/tWByLXvU6Wz4E9vRap+6db/fvCptZr4vTxuazZ1nqNPnzrwj2+S3pfWjd+mL6Z2fmlvqdXn/r7zmdXV3KM6xe65nin1/m7X9PPrtn4IcOrfnQ2j/pbZ5Ew6UCIfZX/n/+2NTd6DTx+/ETWvPbkHff453cv5RibQHB4BL/4AQAAFILGDwAAoBA0fgAAAIWg8QMAACgEjR8AAEAhaPwAAAAKQeMHAABQiHiO317n1SXT+Txt5+cJraZzrtZA5lPSMXJ2vL51jy/3OpSoC+TqtIMOJdqe6yy6JvnZbWl+JcfYBLK7rsZABt/9c/d4nXXO3Kqj82w66DzG5y++lDWnZ/7zvTzT76hvGllTLXrOfPyJP+/MzCYxN/MDvQaerjqXqz3V8zfPfl5W0nFa1lpgQRbgKpAr9vkXeh/90Zefuce3Ii/VzKxqdC7e6U7v+/3gX+/NfifHOB907uD1/bWseXn1l7Jm/FN/wj7e6oy+ttfX+zvf/jVZ895777vHn33tXTnGB3/1F7LmD//Vv5A1Z1d6bv7u73/TPd41+l1/+Vx/p66vdaZdL7JZzcxS5fcTJ52f6WhmNpzotbQ9fSBr2tbPA9x+pp/d4VY/lwh+8QMAACgEjR8AAEAhaPwAAAAKQeMHAABQCBo/AACAQtD4AQAAFILGDwAAoBA0fgAAAIWIBzgfdDDt2uiwz2n2g3KbQCvadTr5N2V9LfvVD5Oekx+4aGbWBEJQq06H1zYWCFzt/FDktdJjDLUOVl5W/RK6+sQ9XgXeYxMIs7VaB3ofr/XzfXzhz7t+1ueZj3pO3QQCp9NRB/Tmxg+Zveh0EHcXCDhdRDizmVkncqsPlb4fW/XzLcH+lR98bmb24uYTWXN948/Fw6DXeZ4/1DV6Olu98T8jd9f6nqtef4qePXqqa954ImuePvQDmn/1V/yQYjOzD37wI1lzd/2prGmqt93jke/Yd/7N92TNd7+nr+Xmxb2sefr4Dff4s/f0858C8+HV8xtZczTdB2ySv+/cX3whx7A7He6fP9T9Ud37/0SgW/QembdfTRA+v/gBAAAUgsYPAACgEDR+AAAAhaDxAwAAKASNHwAAQCFo/AAAAApB4wcAAFAIGj8AAIBChAOcp0BIaxtI7e1rEUiZdDBtXgJB0YsOpk0qVDYPcoxt5YdAm5nZ4ocdm5kdlltZ0z73a54+e02OkWr9XHKjgzGzCBbNs35H46znSyBD27oz/Z5q8wNt50EvhXTUabbjrOfDLEJFzcxOxC11S+DZbfS1pIO+73nrv4Q06fuRa60Q26z30dceXciazZkfKntxupNjtJ3eC64+1mG7V0c/bDeQK2+Xp3oNvxl4LrtL/f042fqJ5Ndf6lDf7aCDdC8v/KBoM7NPP/+he/wHH+jg5e998F1Zs2v1fnE86vnw3/8P/8Q9/u7feF2O0Zl+15udDk3uGh04vd9duseXV3IIqwPvehMIy0/pWgzyQI6xTV/Nb3X84gcAAFAIGj8AAIBC0PgBAAAUgsYPAACgEDR+AAAAhaDxAwAAKASNHwAAQCFo/AAAAAoRDnA2EYBrZpYWXbN0fhhi0+ox1qSDJpdA0GGd/HP1lT5PnXU6ad3rUNFRZybbYH4o8joFBqn88FIzs/Ggg3+XVTxfddxi4czTqt9Bt+j7vrv372lzqsNhl1m/x7bTNc2qQ3zHLNbJXoeXTvNG1rQbPX8nEexaV4Hwaz3tivD+15/JmjfeeSRrkkhF3gb26zaw+3/81sey5gc/+MS/lhO9tqy5kyWPz/QFP9jq+bys/tr5iw++L8ewWgcMf3al98Dlyg82vw7s6bXp/XoYTmXN07fekjWL+CbuDy/lGHWr979tdy5r2l4HZDfZnzNLq/frQM65VY3e4LIYJ9f6Pd7qRxfCL34AAACFoPEDAAAoBI0fAABAIWj8AAAACkHjBwAAUAgaPwAAgELQ+AEAABQinON3DOSpDZtAntfo5xb15zq3aH4lSyxnnc+ziPC8tdd9cSRTcDroe0r5VtbUl/7x46yv5fxC51ztTYcFpdXPsVpWfc/HQJBfPvh5dmZmrxZds4yfusc3W/3sNpH8SNPXsg66JoscP8v+OjIzu046G224H2RNu/MzwOp0kGPc/zUSQ3+RPXumM/qmg36ex0pkfh31/le1en587R2d7fbe66+5xxfT63ze6z3ncPRzTM3MatNrdD36a+fB2VM5RiC2zeyoi9YH/rW8dqLzAt98T2dDHu/0s9sGchL7vHOPX9/5x83McqW/q2dDoA8IZPVOIjO1GnV23rzotXQc9Bzv9/6evt7oa2n7QPhtAL/4AQAAFILGDwAAoBA0fgAAAIWg8QMAACgEjR8AAEAhaPwAAAAKQeMHAABQCBo/AACAQoRjVYdAILLtA0HFotfcf6bDbQO5ytY2OuB2s9u4x1+91PdT7/ayZlp0qOV8vJc1J70/zvnJpRzjwU4/3/Ptuaz56PNP3OOBqWCH+2tZs+RAUuqi3/Xu2RP3+HGvw2ybkzNZswauxeZKliw7P2j7ptXn6QLBoymwrI+zmOOVfkf99NUEj/68OwbW+WHR86Ob/Wfe7fQY1vnB3GZmG52HbCn7+2iadCB1tbnUNY3ea0edg29L9kN9H476A1NVgaD2Vn9eq9Z/j23SY+RKh/LnRzoc+CbpkOfN6ge+v/lm4Nmt+tlVWd/3UunQ77yKfxgR+O1rTXotzSpw38zssf9851G/x6bT7yiCX/wAAAAKQeMHAABQCBo/AACAQtD4AQAAFILGDwAAoBA0fgAAAIWg8QMAACgEjR8AAEAhwgHOkfjVutahsuvkh3BWlR8GamY2mk4V7QMBt+Poj5MHfddT0udpkh7nWOsAyLZ75B4/Pdev83Crw1SHQCDvcvSDJNdjIFwzEGQcCWdOWz1Mu/PDrx881OHMOXC5d4dAoLfp59sexXyY9XxJnf67rs1+IKuZWRbhpEuj59QUCEEtwRoIet0mvQc2IqC5q/QeeZz0PMyBnwbq5Bf1vQ6EXwPfjnnS4bVdr59v1/hrve0CqdWDns950Q8vVX5NHfjWVZV+LlVgk+wCG1yb/etZ28C1dIE9ZwkEZAf2lGbxrzfpS7FqiXzL9DiLmL91q9P06/ar+a2OX/wAAAAKQeMHAABQCBo/AACAQtD4AQAAFILGDwAAoBA0fgAAAIWg8QMAACgEjR8AAEAhwgHObSCEeFkDYZN174+R9BibLhD2edBBknXtnyuS4zlPOmjyNt/Kmr7WSZKvXrxyj//ko8/lGLnRoZf3gcDKSgRj1p0Oo+x1fqzt9eO1utHT+NHFqXt8uLjQ13J1I2v63j+PmdlxHGXNJIKrcyDw+6QOhCa3el3Xq//3YdPq5z8fdMhzCZrWDxI3M1v6wMaT/cWTFn+fNTPLgZD7FAic7hp/fkyBuZrFHDMz68S3w8zsuAlsGLP/7PpzvXetR/3s+kAo9bHxa/pR78VL4LksFghWDgQ4r7MI7g8E7q8bvf81q76WLnBP1vnB1XOg31gCKeZ1pe9blSSxps3MmhS45wB+8QMAACgEjR8AAEAhaPwAAAAKQeMHAABQCBo/AACAQtD4AQAAFILGDwAAoBDhHL/c6HykJpJ7J7KCNif6kqpVZ+Y0Oi7LusnPzutOdJ7TbSAH7bzTmUQpkPn0xcvn7vHqu/odff2dZ7Lmcqcz7T5of+Qe7yudLWXtuSxZF52B2Aaiu1rxCupABuXa6Zyl+5f6b6k86ppU793jy6TXyXbQc2r3SOcOJhGmWC2RFxDean6xzXq/aJN+nmvj7111YF9KOiLOOgvknNVqXQROtOq99ljpa2lavbaG2R8nks3abwN7+j5wveY/u7wJ5OIF5ktOgSy6QEZcJb6JzRL4LSmQnZeTvu8psB/LHMpIXmAg+zbX+tmtk58pmAPBwfWq834j+MUPAACgEDR+AAAAhaDxAwAAKASNHwAAQCFo/AAAAApB4wcAAFAIGj8AAIBC0PgBAAAUIpyq2lU6ODASQrwTub651aGMfa0vO+thLG/9vrdbz+QY3RIIvax1f7050YnTt/29e7zf6ud/eakDnAO5mFY1G/d4Wo5yjJNGBzgvva652Oj5MDz0r3e614G3r+6vZc3NvQ6crhf9nrrOXyjDVoe2tq2eU43p++52/oSYAyGo7RyYVCUIhNfOo3639U7Ms+TPdzOzodHzcKl0TZX9fWlZ9PyoAt+OOuu9djzoZzd3/rNp2kDgdCAQeej1vnTI/j7ZroF/aGCBd1Tp9VcHQojVfUe+uxYIfK9O9PytImHolX+uZIHw+cA/ppiSnuN9d/ALAv91IgX26wh+8QMAACgEjR8AAEAhaPwAAAAKQeMHAABQCBo/AACAQtD4AQAAFILGDwAAoBA0fgAAAIUIBzjnQEjkMOgQwyQCHrtAYGVqIimROuiwWTv3eLsNhDLOIpHazHYn/nnMzM4CAc6np/448xwIBm71Pc1JBE2a2fmFH6w83el73ovwUjOz00Y/37NBB23fvXrpHv/Jl6/kGM+v9HOpA4G3u60OQ29af5yNbQNjjLJmnvRaOlHrutFz6hAIOC1B1QX2t1rvXfXqv7cc2P/mpMNrx1mv49T577ZbA3uxmO9mZktg3z9pTvQ4lVgXoz7PFEj1jUz5uvOfb50Ca3gO7AWdDqXOq95r5yzeZa2fS7bAgwnMmV1gmH3y19u66uudGh1svQ2ElM+Dfy151NeyVl/Nb3X84gcAAFAIGj8AAIBC0PgBAAAUgsYPAACgEDR+AAAAhaDxAwAAKASNHwAAQCFo/AAAAAoRDnDuWh06OwXCa2sRLNoExlhzILlRZyHasvrBjGnS11JVOtyxzjoY826vAytVm55q/Y4+/+JK1lSrDlZuGv/Z5KSfS076747bSl9Lfa3Pdf25H75890IHpeYTHXjbVXpJHW/0OLvaf75jHVi6Wc+H7kTPu8PBD7Q9Vvp+1rvAgixAPuq5Ovd6XdS9/06qWb8TMcV+Ns4mEAo/+edaah0enFodFL0zHaycuq9gngWefxv4dOYlcC1i25nqQKhyIKg9kN9sS9J7wSo+rE3gm2mBb2au9HwYA+HWtQiLzoE51QeaidzpOZMnf840IgjdzKwLBKpH8IsfAABAIWj8AAAACkHjBwAAUAgaPwAAgELQ+AEAABSCxg8AAKAQNH4AAACFCOf41RudH7MNZLc1k99rzo3OnxoCNVMgFm9c/XyevtWZRCmQA9QM+jGfPbiUNcvBv+8Xx1s5xvWNn2dnZlYPG1nz6OLcHyOQM3d4FciQa3RW0yoyBc3MNiL3LD05kWPsAllNN3sdmNU2gVyoxn9+3RD4my3r57JM+lqSiJfabPQY99tA9mYBll4/q27WNevk77W7Vu9LY+CV1DmQRScy1+ZAnt1poy9mDORF9o3+TlWtv7aWQAZik/W3LiW9B47i21AFztOZzutcA5l3adH7cS32JbHN/uw8eSdr2krPh6rS953Etl7Peh+tsv4e5sCz68UwVSAreT7eyZoIfvEDAAAoBI0fAABAIWj8AAAACkHjBwAAUAgaPwAAgELQ+AEAABSCxg8AAKAQNH4AAACFCAc4Hw46+HcbCVQUx7tRh87uWx3uWM86SbKqRehiILy0DdSkVYcDD8NW1nTz3j9e6Wt5dXUla/rzU1nz7Mnr7vHtiR/wbGZ2NegwyuOsQ6l3Z/rZLYs/r9Z7fS3rrMNUc63n5nmnazZbf87ser100xoIdl10sGvVHt3jOevz2PTVBI/+vHt68VDWBPKDzdR8bnSQeLcGEpwDIfZT5a+LTWD/s8C+37T6wdSBBOEkAqVPOh0CfV/r30z6QFC7yjWv6l6OUQW+dfVWX++00fuoreJcG32eNeuaLvB86zpw35UI7g+Ez9eBf0yh/hmEmVlb+fe0VHrN3o2BtRTAL34AAACFoPEDAAAoBI0fAABAIWj8AAAACkHjBwAAUAgaPwAAgELQ+AEAABSCxg8AAKAQVc5ZJ2cCAADg5x6/+AEAABSCxg8AAKAQNH4AAACFoPEDAAAoBI0fAABAIWj8AAAACkHjBwAAUAgaPwAAgELQ+AEAABTi/wbJGg/7P/PdSQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 800x800 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate samples using the trained latent diffusion model\n",
    "dm.eval()\n",
    "dm = dm.to(device)\n",
    "sample = dm.forward(n_samples=4)  # Generate 4 sample images, 'y' represents any conditions, 'gamma' means guidance scale\n",
    "painter.show_images(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5da1251-937b-4e26-a2e0-24bd6107d05a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DiffusionModel(\n",
       "  (sampler): DDIM(\n",
       "    (network): UnetWrapper(\n",
       "      (network): Unet(\n",
       "        (init_conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "        (time_mlp): Sequential(\n",
       "          (0): SinusoidalEmbedding()\n",
       "          (1): Linear(in_features=64, out_features=256, bias=True)\n",
       "          (2): GELU(approximate='none')\n",
       "          (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (downs): ModuleList(\n",
       "          (0): ModuleList(\n",
       "            (0-1): 2 x ResnetBlock(\n",
       "              (block1): Block(\n",
       "                (norm): AdaptiveGroupNorm(\n",
       "                  (norm): GroupNorm(32, 64, eps=1e-05, affine=False)\n",
       "                  (gamma_proj): Linear(in_features=256, out_features=64, bias=True)\n",
       "                  (beta_proj): Linear(in_features=256, out_features=64, bias=True)\n",
       "                )\n",
       "                (proj): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU()\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): AdaptiveGroupNorm(\n",
       "                  (norm): GroupNorm(32, 64, eps=1e-05, affine=False)\n",
       "                  (gamma_proj): Linear(in_features=256, out_features=64, bias=True)\n",
       "                  (beta_proj): Linear(in_features=256, out_features=64, bias=True)\n",
       "                )\n",
       "                (proj): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU()\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (res_conv): Identity()\n",
       "            )\n",
       "            (2): LinearAttention(\n",
       "              (to_qkv): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): RMSNorm()\n",
       "              )\n",
       "            )\n",
       "            (3): DownSample(\n",
       "              (downsample): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (1): ModuleList(\n",
       "            (0-1): 2 x ResnetBlock(\n",
       "              (block1): Block(\n",
       "                (norm): AdaptiveGroupNorm(\n",
       "                  (norm): GroupNorm(32, 128, eps=1e-05, affine=False)\n",
       "                  (gamma_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "                  (beta_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "                )\n",
       "                (proj): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU()\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): AdaptiveGroupNorm(\n",
       "                  (norm): GroupNorm(32, 128, eps=1e-05, affine=False)\n",
       "                  (gamma_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "                  (beta_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "                )\n",
       "                (proj): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU()\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (res_conv): Identity()\n",
       "            )\n",
       "            (2): LinearAttention(\n",
       "              (to_qkv): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): RMSNorm()\n",
       "              )\n",
       "            )\n",
       "            (3): DownSample(\n",
       "              (downsample): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (2): ModuleList(\n",
       "            (0-1): 2 x ResnetBlock(\n",
       "              (block1): Block(\n",
       "                (norm): AdaptiveGroupNorm(\n",
       "                  (norm): GroupNorm(32, 256, eps=1e-05, affine=False)\n",
       "                  (gamma_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "                  (beta_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "                )\n",
       "                (proj): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU()\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): AdaptiveGroupNorm(\n",
       "                  (norm): GroupNorm(32, 256, eps=1e-05, affine=False)\n",
       "                  (gamma_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "                  (beta_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "                )\n",
       "                (proj): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU()\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (res_conv): Identity()\n",
       "            )\n",
       "            (2): LinearAttention(\n",
       "              (to_qkv): Conv2d(256, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): RMSNorm()\n",
       "              )\n",
       "            )\n",
       "            (3): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (ups): ModuleList(\n",
       "          (0): ModuleList(\n",
       "            (0-1): 2 x ResnetBlock(\n",
       "              (block1): Block(\n",
       "                (norm): AdaptiveGroupNorm(\n",
       "                  (norm): GroupNorm(32, 768, eps=1e-05, affine=False)\n",
       "                  (gamma_proj): Linear(in_features=256, out_features=768, bias=True)\n",
       "                  (beta_proj): Linear(in_features=256, out_features=768, bias=True)\n",
       "                )\n",
       "                (proj): Conv2d(768, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU()\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): AdaptiveGroupNorm(\n",
       "                  (norm): GroupNorm(32, 512, eps=1e-05, affine=False)\n",
       "                  (gamma_proj): Linear(in_features=256, out_features=512, bias=True)\n",
       "                  (beta_proj): Linear(in_features=256, out_features=512, bias=True)\n",
       "                )\n",
       "                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU()\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (res_conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (2): Attention(\n",
       "              (to_qkv): Conv2d(512, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (to_out): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (3): UpSample(\n",
       "              (upsample): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (1): ModuleList(\n",
       "            (0-1): 2 x ResnetBlock(\n",
       "              (block1): Block(\n",
       "                (norm): AdaptiveGroupNorm(\n",
       "                  (norm): GroupNorm(32, 384, eps=1e-05, affine=False)\n",
       "                  (gamma_proj): Linear(in_features=256, out_features=384, bias=True)\n",
       "                  (beta_proj): Linear(in_features=256, out_features=384, bias=True)\n",
       "                )\n",
       "                (proj): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU()\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): AdaptiveGroupNorm(\n",
       "                  (norm): GroupNorm(32, 256, eps=1e-05, affine=False)\n",
       "                  (gamma_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "                  (beta_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "                )\n",
       "                (proj): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU()\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (res_conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (2): LinearAttention(\n",
       "              (to_qkv): Conv2d(256, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): RMSNorm()\n",
       "              )\n",
       "            )\n",
       "            (3): UpSample(\n",
       "              (upsample): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (2): ModuleList(\n",
       "            (0-1): 2 x ResnetBlock(\n",
       "              (block1): Block(\n",
       "                (norm): AdaptiveGroupNorm(\n",
       "                  (norm): GroupNorm(32, 192, eps=1e-05, affine=False)\n",
       "                  (gamma_proj): Linear(in_features=256, out_features=192, bias=True)\n",
       "                  (beta_proj): Linear(in_features=256, out_features=192, bias=True)\n",
       "                )\n",
       "                (proj): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU()\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): AdaptiveGroupNorm(\n",
       "                  (norm): GroupNorm(32, 128, eps=1e-05, affine=False)\n",
       "                  (gamma_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "                  (beta_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "                )\n",
       "                (proj): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU()\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (res_conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (2): LinearAttention(\n",
       "              (to_qkv): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): RMSNorm()\n",
       "              )\n",
       "            )\n",
       "            (3): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (mid_block1): ResnetBlock(\n",
       "          (block1): Block(\n",
       "            (norm): AdaptiveGroupNorm(\n",
       "              (norm): GroupNorm(32, 512, eps=1e-05, affine=False)\n",
       "              (gamma_proj): Linear(in_features=256, out_features=512, bias=True)\n",
       "              (beta_proj): Linear(in_features=256, out_features=512, bias=True)\n",
       "            )\n",
       "            (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (block2): Block(\n",
       "            (norm): AdaptiveGroupNorm(\n",
       "              (norm): GroupNorm(32, 512, eps=1e-05, affine=False)\n",
       "              (gamma_proj): Linear(in_features=256, out_features=512, bias=True)\n",
       "              (beta_proj): Linear(in_features=256, out_features=512, bias=True)\n",
       "            )\n",
       "            (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (res_conv): Identity()\n",
       "        )\n",
       "        (mid_attn): Attention(\n",
       "          (to_qkv): Conv2d(512, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (to_out): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (mid_block2): ResnetBlock(\n",
       "          (block1): Block(\n",
       "            (norm): AdaptiveGroupNorm(\n",
       "              (norm): GroupNorm(32, 512, eps=1e-05, affine=False)\n",
       "              (gamma_proj): Linear(in_features=256, out_features=512, bias=True)\n",
       "              (beta_proj): Linear(in_features=256, out_features=512, bias=True)\n",
       "            )\n",
       "            (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (block2): Block(\n",
       "            (norm): AdaptiveGroupNorm(\n",
       "              (norm): GroupNorm(32, 512, eps=1e-05, affine=False)\n",
       "              (gamma_proj): Linear(in_features=256, out_features=512, bias=True)\n",
       "              (beta_proj): Linear(in_features=256, out_features=512, bias=True)\n",
       "            )\n",
       "            (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (res_conv): Identity()\n",
       "        )\n",
       "        (final_res_block): ResnetBlock(\n",
       "          (block1): Block(\n",
       "            (norm): AdaptiveGroupNorm(\n",
       "              (norm): GroupNorm(32, 128, eps=1e-05, affine=False)\n",
       "              (gamma_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "              (beta_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "            )\n",
       "            (proj): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (block2): Block(\n",
       "            (norm): AdaptiveGroupNorm(\n",
       "              (norm): GroupNorm(32, 64, eps=1e-05, affine=False)\n",
       "              (gamma_proj): Linear(in_features=256, out_features=64, bias=True)\n",
       "              (beta_proj): Linear(in_features=256, out_features=64, bias=True)\n",
       "            )\n",
       "            (proj): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (res_conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (final_conv): Conv2d(64, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (cond_encoder): None\n",
       "    )\n",
       "  )\n",
       "  (network): UnetWrapper(\n",
       "    (network): Unet(\n",
       "      (init_conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "      (time_mlp): Sequential(\n",
       "        (0): SinusoidalEmbedding()\n",
       "        (1): Linear(in_features=64, out_features=256, bias=True)\n",
       "        (2): GELU(approximate='none')\n",
       "        (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "      (downs): ModuleList(\n",
       "        (0): ModuleList(\n",
       "          (0-1): 2 x ResnetBlock(\n",
       "            (block1): Block(\n",
       "              (norm): AdaptiveGroupNorm(\n",
       "                (norm): GroupNorm(32, 64, eps=1e-05, affine=False)\n",
       "                (gamma_proj): Linear(in_features=256, out_features=64, bias=True)\n",
       "                (beta_proj): Linear(in_features=256, out_features=64, bias=True)\n",
       "              )\n",
       "              (proj): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (act): SiLU()\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (norm): AdaptiveGroupNorm(\n",
       "                (norm): GroupNorm(32, 64, eps=1e-05, affine=False)\n",
       "                (gamma_proj): Linear(in_features=256, out_features=64, bias=True)\n",
       "                (beta_proj): Linear(in_features=256, out_features=64, bias=True)\n",
       "              )\n",
       "              (proj): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (act): SiLU()\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (res_conv): Identity()\n",
       "          )\n",
       "          (2): LinearAttention(\n",
       "            (to_qkv): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (to_out): Sequential(\n",
       "              (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): RMSNorm()\n",
       "            )\n",
       "          )\n",
       "          (3): DownSample(\n",
       "            (downsample): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (1): ModuleList(\n",
       "          (0-1): 2 x ResnetBlock(\n",
       "            (block1): Block(\n",
       "              (norm): AdaptiveGroupNorm(\n",
       "                (norm): GroupNorm(32, 128, eps=1e-05, affine=False)\n",
       "                (gamma_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "                (beta_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "              )\n",
       "              (proj): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (act): SiLU()\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (norm): AdaptiveGroupNorm(\n",
       "                (norm): GroupNorm(32, 128, eps=1e-05, affine=False)\n",
       "                (gamma_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "                (beta_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "              )\n",
       "              (proj): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (act): SiLU()\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (res_conv): Identity()\n",
       "          )\n",
       "          (2): LinearAttention(\n",
       "            (to_qkv): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (to_out): Sequential(\n",
       "              (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): RMSNorm()\n",
       "            )\n",
       "          )\n",
       "          (3): DownSample(\n",
       "            (downsample): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (2): ModuleList(\n",
       "          (0-1): 2 x ResnetBlock(\n",
       "            (block1): Block(\n",
       "              (norm): AdaptiveGroupNorm(\n",
       "                (norm): GroupNorm(32, 256, eps=1e-05, affine=False)\n",
       "                (gamma_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (beta_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "              )\n",
       "              (proj): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (act): SiLU()\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (norm): AdaptiveGroupNorm(\n",
       "                (norm): GroupNorm(32, 256, eps=1e-05, affine=False)\n",
       "                (gamma_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (beta_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "              )\n",
       "              (proj): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (act): SiLU()\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (res_conv): Identity()\n",
       "          )\n",
       "          (2): LinearAttention(\n",
       "            (to_qkv): Conv2d(256, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (to_out): Sequential(\n",
       "              (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): RMSNorm()\n",
       "            )\n",
       "          )\n",
       "          (3): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (ups): ModuleList(\n",
       "        (0): ModuleList(\n",
       "          (0-1): 2 x ResnetBlock(\n",
       "            (block1): Block(\n",
       "              (norm): AdaptiveGroupNorm(\n",
       "                (norm): GroupNorm(32, 768, eps=1e-05, affine=False)\n",
       "                (gamma_proj): Linear(in_features=256, out_features=768, bias=True)\n",
       "                (beta_proj): Linear(in_features=256, out_features=768, bias=True)\n",
       "              )\n",
       "              (proj): Conv2d(768, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (act): SiLU()\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (norm): AdaptiveGroupNorm(\n",
       "                (norm): GroupNorm(32, 512, eps=1e-05, affine=False)\n",
       "                (gamma_proj): Linear(in_features=256, out_features=512, bias=True)\n",
       "                (beta_proj): Linear(in_features=256, out_features=512, bias=True)\n",
       "              )\n",
       "              (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (act): SiLU()\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (res_conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (2): Attention(\n",
       "            (to_qkv): Conv2d(512, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (to_out): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (3): UpSample(\n",
       "            (upsample): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (1): ModuleList(\n",
       "          (0-1): 2 x ResnetBlock(\n",
       "            (block1): Block(\n",
       "              (norm): AdaptiveGroupNorm(\n",
       "                (norm): GroupNorm(32, 384, eps=1e-05, affine=False)\n",
       "                (gamma_proj): Linear(in_features=256, out_features=384, bias=True)\n",
       "                (beta_proj): Linear(in_features=256, out_features=384, bias=True)\n",
       "              )\n",
       "              (proj): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (act): SiLU()\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (norm): AdaptiveGroupNorm(\n",
       "                (norm): GroupNorm(32, 256, eps=1e-05, affine=False)\n",
       "                (gamma_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (beta_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "              )\n",
       "              (proj): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (act): SiLU()\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (res_conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (2): LinearAttention(\n",
       "            (to_qkv): Conv2d(256, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (to_out): Sequential(\n",
       "              (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): RMSNorm()\n",
       "            )\n",
       "          )\n",
       "          (3): UpSample(\n",
       "            (upsample): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (2): ModuleList(\n",
       "          (0-1): 2 x ResnetBlock(\n",
       "            (block1): Block(\n",
       "              (norm): AdaptiveGroupNorm(\n",
       "                (norm): GroupNorm(32, 192, eps=1e-05, affine=False)\n",
       "                (gamma_proj): Linear(in_features=256, out_features=192, bias=True)\n",
       "                (beta_proj): Linear(in_features=256, out_features=192, bias=True)\n",
       "              )\n",
       "              (proj): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (act): SiLU()\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (norm): AdaptiveGroupNorm(\n",
       "                (norm): GroupNorm(32, 128, eps=1e-05, affine=False)\n",
       "                (gamma_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "                (beta_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "              )\n",
       "              (proj): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (act): SiLU()\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (res_conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (2): LinearAttention(\n",
       "            (to_qkv): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (to_out): Sequential(\n",
       "              (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): RMSNorm()\n",
       "            )\n",
       "          )\n",
       "          (3): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (mid_block1): ResnetBlock(\n",
       "        (block1): Block(\n",
       "          (norm): AdaptiveGroupNorm(\n",
       "            (norm): GroupNorm(32, 512, eps=1e-05, affine=False)\n",
       "            (gamma_proj): Linear(in_features=256, out_features=512, bias=True)\n",
       "            (beta_proj): Linear(in_features=256, out_features=512, bias=True)\n",
       "          )\n",
       "          (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act): SiLU()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (block2): Block(\n",
       "          (norm): AdaptiveGroupNorm(\n",
       "            (norm): GroupNorm(32, 512, eps=1e-05, affine=False)\n",
       "            (gamma_proj): Linear(in_features=256, out_features=512, bias=True)\n",
       "            (beta_proj): Linear(in_features=256, out_features=512, bias=True)\n",
       "          )\n",
       "          (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act): SiLU()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (res_conv): Identity()\n",
       "      )\n",
       "      (mid_attn): Attention(\n",
       "        (to_qkv): Conv2d(512, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (to_out): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (mid_block2): ResnetBlock(\n",
       "        (block1): Block(\n",
       "          (norm): AdaptiveGroupNorm(\n",
       "            (norm): GroupNorm(32, 512, eps=1e-05, affine=False)\n",
       "            (gamma_proj): Linear(in_features=256, out_features=512, bias=True)\n",
       "            (beta_proj): Linear(in_features=256, out_features=512, bias=True)\n",
       "          )\n",
       "          (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act): SiLU()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (block2): Block(\n",
       "          (norm): AdaptiveGroupNorm(\n",
       "            (norm): GroupNorm(32, 512, eps=1e-05, affine=False)\n",
       "            (gamma_proj): Linear(in_features=256, out_features=512, bias=True)\n",
       "            (beta_proj): Linear(in_features=256, out_features=512, bias=True)\n",
       "          )\n",
       "          (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act): SiLU()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (res_conv): Identity()\n",
       "      )\n",
       "      (final_res_block): ResnetBlock(\n",
       "        (block1): Block(\n",
       "          (norm): AdaptiveGroupNorm(\n",
       "            (norm): GroupNorm(32, 128, eps=1e-05, affine=False)\n",
       "            (gamma_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (beta_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "          )\n",
       "          (proj): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act): SiLU()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (block2): Block(\n",
       "          (norm): AdaptiveGroupNorm(\n",
       "            (norm): GroupNorm(32, 64, eps=1e-05, affine=False)\n",
       "            (gamma_proj): Linear(in_features=256, out_features=64, bias=True)\n",
       "            (beta_proj): Linear(in_features=256, out_features=64, bias=True)\n",
       "          )\n",
       "          (proj): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act): SiLU()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (res_conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (final_conv): Conv2d(64, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (cond_encoder): None\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampler=sampler.to(device)\n",
    "dm = dm.to(device)\n",
    "\n",
    "sampler.eval()\n",
    "dm.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf74877-654f-4f37-a50c-3e934cfbcc8f",
   "metadata": {},
   "source": [
    "## compute jacobian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cda24034-5b37-41ff-b9f4-22fbd7c4d983",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch 1: 100%|| 100/100 [12:30<00:00,  7.51s/it]\n"
     ]
    }
   ],
   "source": [
    "N_sim = 1000\n",
    "skip = 10\n",
    "Js = []\n",
    "batch_size = 1\n",
    "\n",
    "def f(x, t):\n",
    "    return dm.network(x, t.long())\n",
    "\n",
    "pbar = tqdm.tqdm(range(1, N_sim, skip))\n",
    "for t_in in pbar:\n",
    "    Js_tmp = []\n",
    "    # reset data\n",
    "    data_loader = data_generator.cifar10(batch_size=batch_size)\n",
    "    for idx, (x0, _) in enumerate(data_loader):\n",
    "        pbar.set_description(f\"batch {idx}\")\n",
    "        if idx >= 1: # collect from 128 images only\n",
    "            break\n",
    "        x0 = x0.to(device)\n",
    "        \n",
    "        t = torch.ones(batch_size,).long().to(device)*t_in\n",
    "        x0_noised = sampler.q_sample(x0, t)\n",
    "        \n",
    "        # get scores & jacobian\n",
    "        \n",
    "        t_grad = t.clone().detach().requires_grad_(False)\n",
    "        x_grad = x0_noised.clone().detach().requires_grad_(True).to(device)\n",
    "        J, _ = torch.autograd.functional.jacobian(f, (x_grad, t_grad.float()), vectorize=True)\n",
    "        Jr = J.reshape(batch_size, 3*32*32, batch_size, 3*32*32)\n",
    "        Js_tmp.append(Jr.cpu().numpy())\n",
    "    Js.append(Js_tmp)\n",
    "\n",
    "np.save(f'stats/jacobian_t{N_sim}', np.array(Js))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f61704d-40dd-4892-a462-dbecaaa14a73",
   "metadata": {},
   "source": [
    "## sample paths methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db1199af-8db6-4fdd-a389-b80ad599ec71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mike_periodic_bridge(x, y, steps):\n",
    "    x = x.detach().cpu().numpy()\n",
    "    y = y.detach().cpu().numpy()\n",
    "    ## split in to pairs of pixels\n",
    "    inds=np.arange(x.size).reshape((-1,1))\n",
    "    xsize = x[0].size #size of 1 image\n",
    "    # shuffle the indices\n",
    "    for i in range(0, xsize*batch_size, xsize):\n",
    "        tmp = inds[i:i+xsize]\n",
    "        np.random.shuffle(tmp)\n",
    "        inds[i:i+xsize] = tmp\n",
    "\n",
    "    s = xsize // 2\n",
    "    ind_pairs = np.array([np.stack((inds[i*s*2:i*s*2 + s], inds[i*s*2 + s:i*s*2 + 2*s])) for i in range(batch_size)])\n",
    "    # print(ind_pairs.shape)\n",
    "    centers = x[np.unravel_index(ind_pairs, x.shape)] # centers[:, i] == x[ind_pairs[0, i]], x[ind_pairs[1, i]] (where indexing is implicitly unraveled)\n",
    "    points = y[np.unravel_index(ind_pairs, y.shape)]\n",
    "    radii = np.sqrt(np.sum((centers - points) ** 2, axis=1))\n",
    "    thetas = np.arctan2((points - centers)[:,1,...], (points - centers)[:,0,...])\n",
    "    # print(centers.shape, points.shape, x.shape)\n",
    "    \n",
    "    radii = radii[:,None,:,:]\n",
    "    thetas = thetas[:,None,:,:]\n",
    "    # print(radii.shape, thetas.shape)\n",
    "    \n",
    "    def make_image(theta, x):\n",
    "        new_points = centers + radii * np.concatenate([np.cos(thetas + theta), np.sin(thetas + theta)], axis=1)\n",
    "\n",
    "        ind_0 = ind_pairs[:,0,...]\n",
    "        ind_1 = ind_pairs[:,1,...]\n",
    "        # print(new_points.shape)\n",
    "        x[np.unravel_index(ind_0, x.shape)] = new_points[:,0,...]\n",
    "        x[np.unravel_index(ind_1, x.shape)] = new_points[:,1,...]\n",
    "        return x\n",
    "        \n",
    "    y_rot = np.zeros_like(x)\n",
    "    bridge = []\n",
    "    for i, theta in enumerate(np.linspace(0, 2*np.pi, steps, endpoint=False)):\n",
    "        y_rot = make_image(theta, y_rot)\n",
    "        bridge.append(torch.from_numpy(y_rot.copy()))\n",
    "\n",
    "    bridge.append(bridge[0]) #closed-loop\n",
    "    return bridge\n",
    "\n",
    "def brownian_bridge(x, steps, sigma, T=1000):\n",
    "    x_t = x.clone()\n",
    "    bridge = [x_t.cpu()]\n",
    "        \n",
    "    # Construct Brownian bridge\n",
    "    for t in range(1, T):\n",
    "        eps = sigma * torch.randn_like(x)\n",
    "        correction = (x - x_t) / (steps - t + 1)\n",
    "        x_t = x_t + eps + correction\n",
    "        bridge.append(x_t.cpu())\n",
    "        \n",
    "    # append initial point to form closed-loop\n",
    "    bridge.append(bridge[0].cpu())\n",
    "    return bridge\n",
    "\n",
    "def cheapshot_bridge(x, steps, t):\n",
    "    # generate steps//10 random images:\n",
    "    bridge_tmp = []\n",
    "    for i in range(steps//10):\n",
    "        noise = torch.randn_like(x)\n",
    "        tin = torch.ones(batch_size).long() * t\n",
    "        xt = sampler.q_sample(x0, tin.to(device))\n",
    "        bridge_tmp.append(xt.cpu())\n",
    "    bridge_tmp.append(bridge_tmp[0]) # close loop\n",
    "    \n",
    "    bridge = [0 for i in range(steps+1)]\n",
    "    bridge[0] = bridge_tmp[0]\n",
    "    bridge[-1] = bridge_tmp[-1]\n",
    "    \n",
    "    for i in range(1, steps):\n",
    "        if i%10 == 0:\n",
    "            bridge[i] = bridge_tmp[i//10]\n",
    "        else:\n",
    "            alpha = (i%10)/10.0\n",
    "            bridge[i] = (1-alpha)*bridge_tmp[i//10] + alpha*bridge_tmp[i//10+1]\n",
    "\n",
    "    return bridge\n",
    "\n",
    "def cheapshot_bridge_yt(x, t, size):\n",
    "    def get_noised(x, t):\n",
    "        tin = torch.ones(x.shape[0]).long() * t\n",
    "        xt = sampler.q_sample(x0, tin.to(device))\n",
    "        return xt\n",
    "        \n",
    "    def interpolate(X0, X1, X2, sqrt_alphas, sqrt_one_minus_alphas, L=100):\n",
    "        # interpolate between X1->X2,\n",
    "        # with projection back on to X0 manifold\n",
    "\n",
    "        # linearly interpolate in between each dimension, as some initial guess\n",
    "        X12 = np.zeros((x.shape[0], L, 3, size, size))\n",
    "        \n",
    "        for b in range(x.shape[0]):\n",
    "            for i in range(size):\n",
    "                for j in range(size):\n",
    "                    for k in range(3):\n",
    "                        X12[b,:,k,i,j] = np.interp( np.linspace(0,1,L), [0,1], [X1[b,k,i,j], X2[b,k,i,j]])\n",
    "    \n",
    "        # matching the gamma from ddpm with YT's\n",
    "        r1 = np.sqrt(np.sum(((X1 - X0*sqrt_alphas)/sqrt_one_minus_alphas)**2))\n",
    "        r2 = np.sqrt(np.sum(((X2 - X0*sqrt_alphas)/sqrt_one_minus_alphas)**2))\n",
    "        r_array = np.interp( np.linspace(0,1,L), [0,1], [r1,r2] ) \n",
    "    \n",
    "        for i in range(L):\n",
    "            unormalized = (X12[:,i,:] - X0*sqrt_alphas)/sqrt_one_minus_alphas\n",
    "            projected = unormalized/ np.sqrt(np.sum(unormalized**2)) * r_array[i] #np.sqrt(32*32*3)\n",
    "            X12[:,i,:] = X0*sqrt_alphas + projected*sqrt_one_minus_alphas\n",
    "    \n",
    "        X12 = torch.from_numpy(X12).permute(1,0,2,3,4).float() # first dim is the path\n",
    "        X12 = list(X12)\n",
    "        return X12\n",
    "    tin = torch.ones(x.shape[0]).long() * t\n",
    "    sqrt_alphas = extract(sampler.alpha_bar, tin.to(device), x.shape).detach().cpu().numpy()\n",
    "    sqrt_one_minus_alphas = 1-sqrt_alphas\n",
    "    \n",
    "    X0 = x.detach().cpu().numpy()\n",
    "\n",
    "    Xs = []\n",
    "    for i in range(10): \n",
    "        Xs.append(get_noised(x, t).detach().cpu().numpy())\n",
    "    Xs.append(Xs[0]) # closed-loop\n",
    "\n",
    "    bridge = [torch.from_numpy(Xs[0])]\n",
    "    for i in range(1,11):\n",
    "        bridge += interpolate(X0, Xs[i-1], Xs[i], sqrt_alphas, sqrt_one_minus_alphas)[1:] # avoid duplicate\n",
    "    \n",
    "    return bridge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc58de9b-5c63-4c75-ace7-ec65bfb84d56",
   "metadata": {},
   "source": [
    "## run score calc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3f1163f-b848-4573-aa96-4c3d0a85706e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "normal path: t_in=991, jdx=0, ddpm_iter=999: 100%|| 100/100 [1:01:53<00:00, 37.13s/it]\n",
      "normal path: t_in=991, jdx=0, ddpm_iter=999: 100%|| 100/100 [1:19:29<00:00, 47.69s/it]\n",
      "normal path: t_in=991, jdx=0, ddpm_iter=989: 100%|| 100/100 [2:13:45<00:00, 80.25s/it] \n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "N_sim = 1000\n",
    "skip = 10\n",
    "T = 1000\n",
    "# for method in ['cheapshot_yt']:\n",
    "for method in ['brownian', 'rotation', 'cheapshot_yt']:\n",
    "    # reset data\n",
    "    test_loader = data_generator.cifar10(batch_size=batch_size)\n",
    "\n",
    "    # save variables\n",
    "    int_list = []\n",
    "    d_list = []\n",
    "    \n",
    "    # method = 'mike'\n",
    "    sigma = 0.05\n",
    "    pbar = tqdm.tqdm(range(1, N_sim, skip))\n",
    "    for t_in in pbar:\n",
    "        max_iter = 1\n",
    "        curr_iter = 0\n",
    "        int_list_tmp = []\n",
    "        d_norm_tmp = []\n",
    "    \n",
    "        \n",
    "        for jdx, (x0,_) in enumerate(iter(test_loader)):\n",
    "            if jdx >= max_iter:\n",
    "                break\n",
    "                \n",
    "            x0 = x0.to(device)\n",
    "            \n",
    "            t = torch.ones(batch_size,).long().to(device)*t_in\n",
    "            x0_noised = sampler.q_sample(x0, t)\n",
    "    \n",
    "            if method == 'brownian':\n",
    "                bridge = brownian_bridge(x0_noised, T, 0.05)\n",
    "            elif method == 'rotation':\n",
    "                bridge = mike_periodic_bridge(x0, x0_noised, T)\n",
    "            elif method == 'cheapshot':\n",
    "                bridge = cheapshot_bridge(x0, T, t_in)\n",
    "            elif method == 'cheapshot_yt':\n",
    "                bridge = cheapshot_bridge_yt(x0, t_in, size=32)\n",
    "            else:\n",
    "                raise('You fucked up')\n",
    "    \n",
    "            # NORMAL PATH\n",
    "            # calculate midpoint\n",
    "            bridge_midpoint = []\n",
    "            for i in range(len(bridge)-1):\n",
    "                mid = (bridge[i] + bridge[i+1])/2\n",
    "                bridge_midpoint.append(mid.cpu())\n",
    "        \n",
    "            # get scores\n",
    "            scores = []\n",
    "            t = torch.ones(batch_size,).to(device) * t_in\n",
    "            t = t.long()\n",
    "            for idx, xb in enumerate(bridge_midpoint):\n",
    "                pbar.set_description(f\"normal path: t_in={t_in}, jdx={jdx}, ddpm_iter={idx}\")\n",
    "                pred_n = dm.network(xb.to(device), t).detach().cpu()\n",
    "                sqrt_alphas = extract(sampler.alpha_bar, t.to(device), x0.shape).detach().cpu()\n",
    "                sqrt_one_minus_alphas = 1-sqrt_alphas\n",
    "                scores.append(-pred_n/sqrt_one_minus_alphas)\n",
    "    \n",
    "            # get directions\n",
    "            dirs = []\n",
    "            for i in range(1, len(bridge)):\n",
    "                dirs.append(bridge[i].cpu()-bridge[i-1].cpu())\n",
    "            # path len\n",
    "                \n",
    "            # integrate\n",
    "            int_res = np.zeros(batch_size)\n",
    "            for s, d in zip(scores, dirs):\n",
    "                # calculate matrix inner prod of a batch\n",
    "                # dxs = torch.einsum('ijkl,ijlm->ijkm', s, d) # <A.T,B>\n",
    "                # norm = torch.vmap(torch.trace)(dxs[:,0,:,:]).numpy().ravel() # trace(<A,B>)\n",
    "    \n",
    "                dxs = s*d\n",
    "                norm = torch.sum(dxs, (1,2,3)).numpy().ravel()\n",
    "                int_res += norm\n",
    "                \n",
    "            d_norm = np.zeros(batch_size)\n",
    "            for i in range(len(dirs)):\n",
    "                for j in range(batch_size):\n",
    "                    d_norm[j] += np.linalg.norm(dirs[i][j])\n",
    "                \n",
    "            int_list_tmp += list(int_res)\n",
    "            d_norm_tmp += list(d_norm)\n",
    "        \n",
    "        int_list.append(int_list_tmp)\n",
    "        d_list.append(d_norm_tmp)\n",
    "\n",
    "    dict_save = {\n",
    "        'int_array': np.array(int_list),\n",
    "        'd_array': np.array(d_list)\n",
    "    }\n",
    "\n",
    "    # np.save(f'stats/{method}_walk_t{N_sim}_untrained_simplified', dict_save)\n",
    "    np.save(f'stats/{method}_walk_t{N_sim}_simplified', dict_save)\n",
    "\n",
    "    del dict_save # save some memory \n",
    "        \n",
    "    # int_array = np.array(int_list)\n",
    "    # np.save(f'{method}_normal_walk_t1000', int_array)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d726017-57c2-416d-9a1b-f9676f552bf4",
   "metadata": {},
   "source": [
    "### normal boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8924272-8ada-4c0b-b5d9-d71c1d3a5629",
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'cheapshot_yt'\n",
    "int_array = np.load(f'{method}_ldm_normal_walk_t100.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e2df77-0e72-47c0-bef9-ca6f6d357f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = list(range(1, 100, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548043bf-834b-48ba-a3f7-617a7eab2426",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,5))\n",
    "plt.boxplot(list(int_array[:10]), tick_labels=ind)\n",
    "plt.ylabel('scores integration')\n",
    "plt.xlabel('tk')\n",
    "plt.xticks(rotation=70)\n",
    "plt.title(f\"{method} - latent diffusion\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2605e66-a287-4816-911b-70f698d14e0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diff",
   "language": "python",
   "name": "diff"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
