{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9abb6f1-3365-405b-a084-0aac9590fe1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/hpc/share/vuonga2/conda-env/diff/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "\n",
    "import torch\n",
    "\n",
    "from helper.painter import Painter\n",
    "from helper.trainer import Trainer\n",
    "from helper.data_generator import DataGenerator\n",
    "from helper.loader import Loader\n",
    "from helper.cond_encoder import CLIPEncoder\n",
    "\n",
    "from auto_encoder.models.variational_auto_encoder import VariationalAutoEncoder\n",
    "from clip.models.ko_clip import KoCLIPWrapper\n",
    "from diffusion_model.sampler.ddim import DDIM\n",
    "from diffusion_model.models.latent_diffusion_model import DiffusionModel\n",
    "from diffusion_model.network.unet import Unet\n",
    "from diffusion_model.network.unet_wrapper import UnetWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57e2dc21-55bc-4013-af6d-46cc219ad188",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from helper.util import extract\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b803a392-d1b6-43d4-b6b0-d459e8576e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the configuration file\n",
    "CONFIG_PATH = './configs/cifar10_config.yaml'\n",
    "\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda')\n",
    "\n",
    "# Instantiate helper classes\n",
    "painter = Painter()\n",
    "loader = Loader()\n",
    "data_generator = DataGenerator()\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "data_loader = data_generator.cifar10(batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e586442-6c70-4ec8-9dec-543d4a66b314",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sampler = DDIM(CONFIG_PATH)  # Initialize the DDIM sampler\n",
    "network = UnetWrapper(Unet, CONFIG_PATH, None)  # Initialize the U-Net network\n",
    "dm = DiffusionModel(network, sampler, [3,32,32])  # Initialize the LDM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b49cd40e-16b8-4e28-84a4-0dabfeab5d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 707\n",
      "Training step: 34643\n",
      "Best loss: 0.017362909505561908\n",
      "Batch size: 1024\n",
      "Number of batches: 49\n",
      "===Model loaded!===\n"
     ]
    }
   ],
   "source": [
    "dm = loader.model_load('models/cifar10/dm', dm, is_ema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f3c56c3-74ac-459c-9fa3-7733223361b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:00, 84.22it/s] \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate samples using the trained latent diffusion model\n",
    "dm.eval()\n",
    "dm = dm.to(device)\n",
    "sample = dm.forward(n_samples=4)  # Generate 4 sample images, 'y' represents any conditions, 'gamma' means guidance scale\n",
    "painter.show_images(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c829e435-402d-44cf-ac80-aaeda7745c32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DiffusionModel(\n",
       "  (sampler): DDIM(\n",
       "    (network): UnetWrapper(\n",
       "      (network): Unet(\n",
       "        (init_conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "        (time_mlp): Sequential(\n",
       "          (0): SinusoidalEmbedding()\n",
       "          (1): Linear(in_features=64, out_features=256, bias=True)\n",
       "          (2): GELU(approximate='none')\n",
       "          (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (downs): ModuleList(\n",
       "          (0): ModuleList(\n",
       "            (0-1): 2 x ResnetBlock(\n",
       "              (block1): Block(\n",
       "                (norm): AdaptiveGroupNorm(\n",
       "                  (norm): GroupNorm(32, 64, eps=1e-05, affine=False)\n",
       "                  (gamma_proj): Linear(in_features=256, out_features=64, bias=True)\n",
       "                  (beta_proj): Linear(in_features=256, out_features=64, bias=True)\n",
       "                )\n",
       "                (proj): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU()\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): AdaptiveGroupNorm(\n",
       "                  (norm): GroupNorm(32, 64, eps=1e-05, affine=False)\n",
       "                  (gamma_proj): Linear(in_features=256, out_features=64, bias=True)\n",
       "                  (beta_proj): Linear(in_features=256, out_features=64, bias=True)\n",
       "                )\n",
       "                (proj): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU()\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (res_conv): Identity()\n",
       "            )\n",
       "            (2): LinearAttention(\n",
       "              (to_qkv): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): RMSNorm()\n",
       "              )\n",
       "            )\n",
       "            (3): DownSample(\n",
       "              (downsample): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (1): ModuleList(\n",
       "            (0-1): 2 x ResnetBlock(\n",
       "              (block1): Block(\n",
       "                (norm): AdaptiveGroupNorm(\n",
       "                  (norm): GroupNorm(32, 128, eps=1e-05, affine=False)\n",
       "                  (gamma_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "                  (beta_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "                )\n",
       "                (proj): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU()\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): AdaptiveGroupNorm(\n",
       "                  (norm): GroupNorm(32, 128, eps=1e-05, affine=False)\n",
       "                  (gamma_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "                  (beta_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "                )\n",
       "                (proj): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU()\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (res_conv): Identity()\n",
       "            )\n",
       "            (2): LinearAttention(\n",
       "              (to_qkv): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): RMSNorm()\n",
       "              )\n",
       "            )\n",
       "            (3): DownSample(\n",
       "              (downsample): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (2): ModuleList(\n",
       "            (0-1): 2 x ResnetBlock(\n",
       "              (block1): Block(\n",
       "                (norm): AdaptiveGroupNorm(\n",
       "                  (norm): GroupNorm(32, 256, eps=1e-05, affine=False)\n",
       "                  (gamma_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "                  (beta_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "                )\n",
       "                (proj): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU()\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): AdaptiveGroupNorm(\n",
       "                  (norm): GroupNorm(32, 256, eps=1e-05, affine=False)\n",
       "                  (gamma_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "                  (beta_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "                )\n",
       "                (proj): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU()\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (res_conv): Identity()\n",
       "            )\n",
       "            (2): LinearAttention(\n",
       "              (to_qkv): Conv2d(256, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): RMSNorm()\n",
       "              )\n",
       "            )\n",
       "            (3): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (ups): ModuleList(\n",
       "          (0): ModuleList(\n",
       "            (0-1): 2 x ResnetBlock(\n",
       "              (block1): Block(\n",
       "                (norm): AdaptiveGroupNorm(\n",
       "                  (norm): GroupNorm(32, 768, eps=1e-05, affine=False)\n",
       "                  (gamma_proj): Linear(in_features=256, out_features=768, bias=True)\n",
       "                  (beta_proj): Linear(in_features=256, out_features=768, bias=True)\n",
       "                )\n",
       "                (proj): Conv2d(768, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU()\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): AdaptiveGroupNorm(\n",
       "                  (norm): GroupNorm(32, 512, eps=1e-05, affine=False)\n",
       "                  (gamma_proj): Linear(in_features=256, out_features=512, bias=True)\n",
       "                  (beta_proj): Linear(in_features=256, out_features=512, bias=True)\n",
       "                )\n",
       "                (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU()\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (res_conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (2): Attention(\n",
       "              (to_qkv): Conv2d(512, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (to_out): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (3): UpSample(\n",
       "              (upsample): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (1): ModuleList(\n",
       "            (0-1): 2 x ResnetBlock(\n",
       "              (block1): Block(\n",
       "                (norm): AdaptiveGroupNorm(\n",
       "                  (norm): GroupNorm(32, 384, eps=1e-05, affine=False)\n",
       "                  (gamma_proj): Linear(in_features=256, out_features=384, bias=True)\n",
       "                  (beta_proj): Linear(in_features=256, out_features=384, bias=True)\n",
       "                )\n",
       "                (proj): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU()\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): AdaptiveGroupNorm(\n",
       "                  (norm): GroupNorm(32, 256, eps=1e-05, affine=False)\n",
       "                  (gamma_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "                  (beta_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "                )\n",
       "                (proj): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU()\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (res_conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (2): LinearAttention(\n",
       "              (to_qkv): Conv2d(256, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): RMSNorm()\n",
       "              )\n",
       "            )\n",
       "            (3): UpSample(\n",
       "              (upsample): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (2): ModuleList(\n",
       "            (0-1): 2 x ResnetBlock(\n",
       "              (block1): Block(\n",
       "                (norm): AdaptiveGroupNorm(\n",
       "                  (norm): GroupNorm(32, 192, eps=1e-05, affine=False)\n",
       "                  (gamma_proj): Linear(in_features=256, out_features=192, bias=True)\n",
       "                  (beta_proj): Linear(in_features=256, out_features=192, bias=True)\n",
       "                )\n",
       "                (proj): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU()\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): AdaptiveGroupNorm(\n",
       "                  (norm): GroupNorm(32, 128, eps=1e-05, affine=False)\n",
       "                  (gamma_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "                  (beta_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "                )\n",
       "                (proj): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU()\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (res_conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (2): LinearAttention(\n",
       "              (to_qkv): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): RMSNorm()\n",
       "              )\n",
       "            )\n",
       "            (3): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (mid_block1): ResnetBlock(\n",
       "          (block1): Block(\n",
       "            (norm): AdaptiveGroupNorm(\n",
       "              (norm): GroupNorm(32, 512, eps=1e-05, affine=False)\n",
       "              (gamma_proj): Linear(in_features=256, out_features=512, bias=True)\n",
       "              (beta_proj): Linear(in_features=256, out_features=512, bias=True)\n",
       "            )\n",
       "            (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (block2): Block(\n",
       "            (norm): AdaptiveGroupNorm(\n",
       "              (norm): GroupNorm(32, 512, eps=1e-05, affine=False)\n",
       "              (gamma_proj): Linear(in_features=256, out_features=512, bias=True)\n",
       "              (beta_proj): Linear(in_features=256, out_features=512, bias=True)\n",
       "            )\n",
       "            (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (res_conv): Identity()\n",
       "        )\n",
       "        (mid_attn): Attention(\n",
       "          (to_qkv): Conv2d(512, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (to_out): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (mid_block2): ResnetBlock(\n",
       "          (block1): Block(\n",
       "            (norm): AdaptiveGroupNorm(\n",
       "              (norm): GroupNorm(32, 512, eps=1e-05, affine=False)\n",
       "              (gamma_proj): Linear(in_features=256, out_features=512, bias=True)\n",
       "              (beta_proj): Linear(in_features=256, out_features=512, bias=True)\n",
       "            )\n",
       "            (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (block2): Block(\n",
       "            (norm): AdaptiveGroupNorm(\n",
       "              (norm): GroupNorm(32, 512, eps=1e-05, affine=False)\n",
       "              (gamma_proj): Linear(in_features=256, out_features=512, bias=True)\n",
       "              (beta_proj): Linear(in_features=256, out_features=512, bias=True)\n",
       "            )\n",
       "            (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (res_conv): Identity()\n",
       "        )\n",
       "        (final_res_block): ResnetBlock(\n",
       "          (block1): Block(\n",
       "            (norm): AdaptiveGroupNorm(\n",
       "              (norm): GroupNorm(32, 128, eps=1e-05, affine=False)\n",
       "              (gamma_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "              (beta_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "            )\n",
       "            (proj): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (block2): Block(\n",
       "            (norm): AdaptiveGroupNorm(\n",
       "              (norm): GroupNorm(32, 64, eps=1e-05, affine=False)\n",
       "              (gamma_proj): Linear(in_features=256, out_features=64, bias=True)\n",
       "              (beta_proj): Linear(in_features=256, out_features=64, bias=True)\n",
       "            )\n",
       "            (proj): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (res_conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (final_conv): Conv2d(64, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (cond_encoder): None\n",
       "    )\n",
       "  )\n",
       "  (network): UnetWrapper(\n",
       "    (network): Unet(\n",
       "      (init_conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "      (time_mlp): Sequential(\n",
       "        (0): SinusoidalEmbedding()\n",
       "        (1): Linear(in_features=64, out_features=256, bias=True)\n",
       "        (2): GELU(approximate='none')\n",
       "        (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "      (downs): ModuleList(\n",
       "        (0): ModuleList(\n",
       "          (0-1): 2 x ResnetBlock(\n",
       "            (block1): Block(\n",
       "              (norm): AdaptiveGroupNorm(\n",
       "                (norm): GroupNorm(32, 64, eps=1e-05, affine=False)\n",
       "                (gamma_proj): Linear(in_features=256, out_features=64, bias=True)\n",
       "                (beta_proj): Linear(in_features=256, out_features=64, bias=True)\n",
       "              )\n",
       "              (proj): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (act): SiLU()\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (norm): AdaptiveGroupNorm(\n",
       "                (norm): GroupNorm(32, 64, eps=1e-05, affine=False)\n",
       "                (gamma_proj): Linear(in_features=256, out_features=64, bias=True)\n",
       "                (beta_proj): Linear(in_features=256, out_features=64, bias=True)\n",
       "              )\n",
       "              (proj): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (act): SiLU()\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (res_conv): Identity()\n",
       "          )\n",
       "          (2): LinearAttention(\n",
       "            (to_qkv): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (to_out): Sequential(\n",
       "              (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): RMSNorm()\n",
       "            )\n",
       "          )\n",
       "          (3): DownSample(\n",
       "            (downsample): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (1): ModuleList(\n",
       "          (0-1): 2 x ResnetBlock(\n",
       "            (block1): Block(\n",
       "              (norm): AdaptiveGroupNorm(\n",
       "                (norm): GroupNorm(32, 128, eps=1e-05, affine=False)\n",
       "                (gamma_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "                (beta_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "              )\n",
       "              (proj): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (act): SiLU()\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (norm): AdaptiveGroupNorm(\n",
       "                (norm): GroupNorm(32, 128, eps=1e-05, affine=False)\n",
       "                (gamma_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "                (beta_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "              )\n",
       "              (proj): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (act): SiLU()\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (res_conv): Identity()\n",
       "          )\n",
       "          (2): LinearAttention(\n",
       "            (to_qkv): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (to_out): Sequential(\n",
       "              (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): RMSNorm()\n",
       "            )\n",
       "          )\n",
       "          (3): DownSample(\n",
       "            (downsample): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (2): ModuleList(\n",
       "          (0-1): 2 x ResnetBlock(\n",
       "            (block1): Block(\n",
       "              (norm): AdaptiveGroupNorm(\n",
       "                (norm): GroupNorm(32, 256, eps=1e-05, affine=False)\n",
       "                (gamma_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (beta_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "              )\n",
       "              (proj): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (act): SiLU()\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (norm): AdaptiveGroupNorm(\n",
       "                (norm): GroupNorm(32, 256, eps=1e-05, affine=False)\n",
       "                (gamma_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (beta_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "              )\n",
       "              (proj): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (act): SiLU()\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (res_conv): Identity()\n",
       "          )\n",
       "          (2): LinearAttention(\n",
       "            (to_qkv): Conv2d(256, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (to_out): Sequential(\n",
       "              (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): RMSNorm()\n",
       "            )\n",
       "          )\n",
       "          (3): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (ups): ModuleList(\n",
       "        (0): ModuleList(\n",
       "          (0-1): 2 x ResnetBlock(\n",
       "            (block1): Block(\n",
       "              (norm): AdaptiveGroupNorm(\n",
       "                (norm): GroupNorm(32, 768, eps=1e-05, affine=False)\n",
       "                (gamma_proj): Linear(in_features=256, out_features=768, bias=True)\n",
       "                (beta_proj): Linear(in_features=256, out_features=768, bias=True)\n",
       "              )\n",
       "              (proj): Conv2d(768, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (act): SiLU()\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (norm): AdaptiveGroupNorm(\n",
       "                (norm): GroupNorm(32, 512, eps=1e-05, affine=False)\n",
       "                (gamma_proj): Linear(in_features=256, out_features=512, bias=True)\n",
       "                (beta_proj): Linear(in_features=256, out_features=512, bias=True)\n",
       "              )\n",
       "              (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (act): SiLU()\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (res_conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (2): Attention(\n",
       "            (to_qkv): Conv2d(512, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (to_out): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (3): UpSample(\n",
       "            (upsample): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (1): ModuleList(\n",
       "          (0-1): 2 x ResnetBlock(\n",
       "            (block1): Block(\n",
       "              (norm): AdaptiveGroupNorm(\n",
       "                (norm): GroupNorm(32, 384, eps=1e-05, affine=False)\n",
       "                (gamma_proj): Linear(in_features=256, out_features=384, bias=True)\n",
       "                (beta_proj): Linear(in_features=256, out_features=384, bias=True)\n",
       "              )\n",
       "              (proj): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (act): SiLU()\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (norm): AdaptiveGroupNorm(\n",
       "                (norm): GroupNorm(32, 256, eps=1e-05, affine=False)\n",
       "                (gamma_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (beta_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "              )\n",
       "              (proj): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (act): SiLU()\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (res_conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (2): LinearAttention(\n",
       "            (to_qkv): Conv2d(256, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (to_out): Sequential(\n",
       "              (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): RMSNorm()\n",
       "            )\n",
       "          )\n",
       "          (3): UpSample(\n",
       "            (upsample): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (2): ModuleList(\n",
       "          (0-1): 2 x ResnetBlock(\n",
       "            (block1): Block(\n",
       "              (norm): AdaptiveGroupNorm(\n",
       "                (norm): GroupNorm(32, 192, eps=1e-05, affine=False)\n",
       "                (gamma_proj): Linear(in_features=256, out_features=192, bias=True)\n",
       "                (beta_proj): Linear(in_features=256, out_features=192, bias=True)\n",
       "              )\n",
       "              (proj): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (act): SiLU()\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (norm): AdaptiveGroupNorm(\n",
       "                (norm): GroupNorm(32, 128, eps=1e-05, affine=False)\n",
       "                (gamma_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "                (beta_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "              )\n",
       "              (proj): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (act): SiLU()\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (res_conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (2): LinearAttention(\n",
       "            (to_qkv): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (to_out): Sequential(\n",
       "              (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): RMSNorm()\n",
       "            )\n",
       "          )\n",
       "          (3): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (mid_block1): ResnetBlock(\n",
       "        (block1): Block(\n",
       "          (norm): AdaptiveGroupNorm(\n",
       "            (norm): GroupNorm(32, 512, eps=1e-05, affine=False)\n",
       "            (gamma_proj): Linear(in_features=256, out_features=512, bias=True)\n",
       "            (beta_proj): Linear(in_features=256, out_features=512, bias=True)\n",
       "          )\n",
       "          (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act): SiLU()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (block2): Block(\n",
       "          (norm): AdaptiveGroupNorm(\n",
       "            (norm): GroupNorm(32, 512, eps=1e-05, affine=False)\n",
       "            (gamma_proj): Linear(in_features=256, out_features=512, bias=True)\n",
       "            (beta_proj): Linear(in_features=256, out_features=512, bias=True)\n",
       "          )\n",
       "          (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act): SiLU()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (res_conv): Identity()\n",
       "      )\n",
       "      (mid_attn): Attention(\n",
       "        (to_qkv): Conv2d(512, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (to_out): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (mid_block2): ResnetBlock(\n",
       "        (block1): Block(\n",
       "          (norm): AdaptiveGroupNorm(\n",
       "            (norm): GroupNorm(32, 512, eps=1e-05, affine=False)\n",
       "            (gamma_proj): Linear(in_features=256, out_features=512, bias=True)\n",
       "            (beta_proj): Linear(in_features=256, out_features=512, bias=True)\n",
       "          )\n",
       "          (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act): SiLU()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (block2): Block(\n",
       "          (norm): AdaptiveGroupNorm(\n",
       "            (norm): GroupNorm(32, 512, eps=1e-05, affine=False)\n",
       "            (gamma_proj): Linear(in_features=256, out_features=512, bias=True)\n",
       "            (beta_proj): Linear(in_features=256, out_features=512, bias=True)\n",
       "          )\n",
       "          (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act): SiLU()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (res_conv): Identity()\n",
       "      )\n",
       "      (final_res_block): ResnetBlock(\n",
       "        (block1): Block(\n",
       "          (norm): AdaptiveGroupNorm(\n",
       "            (norm): GroupNorm(32, 128, eps=1e-05, affine=False)\n",
       "            (gamma_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (beta_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "          )\n",
       "          (proj): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act): SiLU()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (block2): Block(\n",
       "          (norm): AdaptiveGroupNorm(\n",
       "            (norm): GroupNorm(32, 64, eps=1e-05, affine=False)\n",
       "            (gamma_proj): Linear(in_features=256, out_features=64, bias=True)\n",
       "            (beta_proj): Linear(in_features=256, out_features=64, bias=True)\n",
       "          )\n",
       "          (proj): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act): SiLU()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (res_conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (final_conv): Conv2d(64, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (cond_encoder): None\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampler=sampler.to(device)\n",
    "dm = dm.to(device)\n",
    "\n",
    "sampler.eval()\n",
    "dm.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0650fe63-b665-4735-8ef1-46bb1ce29363",
   "metadata": {},
   "outputs": [],
   "source": [
    "sqrt_one_minus_alphas_cumprod = 1-sampler.alpha_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "465f28c1-b893-4ed9-b507-6ceb768c771b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch.func import vmap, jvp\n",
    "\n",
    "def f_only_x_one(x1, t1):\n",
    "    # x1: (1,1,H,W); t1: (1,) or scalar-like\n",
    "    t1b = t1.view(1)\n",
    "    # denom = sqrt_one_minus_alphas_cumprod[t1b.long()].reshape(1,1,1,1).detach()\n",
    "    return dm.network(x1, t1b.long())   # -> (1,1,H,W)\n",
    "\n",
    "def f_flat_one(x1, t1):\n",
    "    return f_only_x_one(x1, t1).reshape(-1)     # -> (N=H*W,)\n",
    "\n",
    "# per-sample sub-Jacobian on the SAME input/output indices\n",
    "def subjac_one_sample_same_points(x1, t1, idxs1, chunk=None):\n",
    "    \"\"\"\n",
    "    x1:    (1,1,H,W)            single sample\n",
    "    t1:    (1,)                 single timestep\n",
    "    idxs1: (K,)                 same set for input & output\n",
    "    chunk: int or None          optional micro-batch over K\n",
    "\n",
    "    returns: J_sub (K,K), diag (K,)\n",
    "    \"\"\"\n",
    "    N = x1.numel()                       # = H*W (since C=1)\n",
    "    K = idxs1.numel()\n",
    "\n",
    "    def jvp_one(v_i):\n",
    "        # returns J v_i (shape N,)\n",
    "        return jvp(lambda z: f_flat_one(z, t1), (x1,), (v_i,))[1]\n",
    "\n",
    "    if chunk is None:\n",
    "        V = F.one_hot(idxs1, num_classes=N).to(x1).view(K, *x1.shape)   # (K,1,1,H,W)\n",
    "        Jvs = vmap(jvp_one)(V)                                          # (K, N)\n",
    "    else:\n",
    "        parts = []\n",
    "        for part in idxs1.split(chunk):\n",
    "            Vp = F.one_hot(part, num_classes=N).to(x1).view(-1, *x1.shape)\n",
    "            parts.append(vmap(jvp_one)(Vp))                              # (c, N)\n",
    "        Jvs = torch.cat(parts, dim=0)                                    # (K, N)\n",
    "\n",
    "    J_sub = Jvs[:, idxs1].T.contiguous()                                 # (K, K)\n",
    "    diag  = Jvs[torch.arange(K, device=x1.device), idxs1].contiguous()   # (K,)\n",
    "    return J_sub, diag\n",
    "\n",
    "# batch wrapper: loop over B in Python (no vmap over batch)\n",
    "def subjac_batch_same_points(x, t, idxs_flat, per_sample=False, chunk=None):\n",
    "    \"\"\"\n",
    "    x:          (B,1,H,W)\n",
    "    t:          (B,)\n",
    "    idxs_flat:  (K,) if per_sample=False (shared points across batch)\n",
    "                (B,K) if per_sample=True  (different points per sample)\n",
    "    returns: J_sub (B,K,K), diag (B,K)\n",
    "    \"\"\"\n",
    "    B = x.size(0)\n",
    "    J_list, d_list = [], []\n",
    "    for b in range(B):\n",
    "        idxs_b = idxs_flat[b] if per_sample else idxs_flat\n",
    "        Jb, db = subjac_one_sample_same_points(x[b:b+1], t[b:b+1], idxs_b, chunk=chunk)\n",
    "        J_list.append(Jb)\n",
    "        d_list.append(db)\n",
    "    return torch.stack(J_list, dim=0), torch.stack(d_list, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0611626-ab80-41b4-b223-3a5caa94efb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch 14:   0%|          | 0/100 [00:12<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "N_sim = 1000\n",
    "skip = 10\n",
    "Js = []\n",
    "batch_size = 4\n",
    "C, H, W = 3, 32, 32\n",
    "K = 64\n",
    "pbar = tqdm.tqdm(range(1, N_sim, skip))\n",
    "for t_in in pbar:\n",
    "    Js_tmp = []\n",
    "    # reset data\n",
    "    data_loader = data_generator.cifar10(batch_size=batch_size, shuffle=False)\n",
    "    for idx, (x0, _) in enumerate(data_loader):\n",
    "        pbar.set_description(f\"batch {idx}\")\n",
    "        if idx >= 32: # collect from 128 images only\n",
    "            break\n",
    "        x0 = x0.to(device)\n",
    "        \n",
    "        t = torch.ones(batch_size,).long().to(device)*t_in\n",
    "        x0_noised = sampler.q_sample(x0, t)\n",
    "        \n",
    "        # get scores & jacobian\n",
    "        \n",
    "        idxs_per = torch.stack([torch.randperm(C*H*W, device=x0_noised.device)[:K] for _ in range(batch_size)], dim=0)\n",
    "        J_sub, _ = subjac_batch_same_points(x0_noised, t, idxs_per, per_sample=True, chunk=16) # (batch, 64, 64)\n",
    "        \n",
    "        Js_tmp.append(J_sub.detach().cpu().numpy())\n",
    "    Js.append(np.vstack(Js_tmp))\n",
    "\n",
    "np.save(f'stats/jacobian_t{N_sim}', np.array(Js))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60a146f-f950-43a6-854f-53663ef982b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diff",
   "language": "python",
   "name": "diff"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
